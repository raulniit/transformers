{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5054b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.transformers import BertTokenizer, BertForMaskedLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e08dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "andmed = pd.read_csv(\"Rubric_data/estonianvalence.csv\", encoding = \"utf8\", on_bad_lines='skip', header = None, \n",
    "                     names = [\"rubric\",\"url\", \"order\", \"sentiment\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9207c55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rubric</th>\n",
       "      <th>url</th>\n",
       "      <th>order</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>1</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>Enam kui kümme aastat tagasi tegutses huumorisaates «Wremja» inspektor Kukeke, kes kogu aeg vingus väikese palga pärast ja vaatas, mida saaks töö juurest koju tassida. Stsenaristid Andrus Kivirähk ja Mart Juur olid Kukekese isikusse kokku valanud kõik, mis 1990. aastate Eesti politseinikke halvast küljest iseloomustas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>2</td>\n",
       "      <td>vastuoluline</td>\n",
       "      <td>Neid ridu kirjutades tundub isegi ebaviisakas seda karikatuurset kuju meenutada. Juba saate eetrisse mineku ajal oli tegemist vaatega ajalukku. Politsei on vabanenud üleminekuajal parema puudumisel palgatud juhuseotsijatest. Samuti jõudis ühena esimestest politseijuhtideni arusaamine, et avalik kaeblemine palkade üle ei tule ühelegi organisatsioonile kasuks – kannatab maine ja raha juurde ei tule.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>3</td>\n",
       "      <td>positiivne</td>\n",
       "      <td>Isiklikult kohtasin natukegi Kukekese moodi politseinikku viimati kaheksa aasta eest Lätis. Eranditult kõik viimase kümnendi kokkupuuted politseiametnikega on kinnitanud: vaatamata raskustele on Eesti riik suutnud korrakaitsjateks värvata inimesi, kes on arukad, kohusetundlikud, lugupidamist sisendavas füüsilises vormis ja hea väljendusoskusega.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>4</td>\n",
       "      <td>vastuoluline</td>\n",
       "      <td>Olen näinud ka, kuidas patrull korrarikkujat taltsutab, ning suur osa sellest seisnes enesekindlas olekus ning vastuvaidlemist välistavalt, kuid rahulikult antud korraldustes. Aprillirahutuste ajal veendusime, et Eesti politsei suudab käituda ründajatega väga karmilt. Vaevalt et mitmeks tunniks näoli porisele asfaldile pandud märatsejat lohutas, et kohus hiljem teda riigijuhtide lubatud viisil aastateks vangi ei pannud.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>5</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>Kummaline on nüüd äkki lugeda politsei ja siseministeeriumi ametnike kurtmist kohtu poolt politseinike ründajatele (lihtsalt öeldes – peksjatele) määratud karistuste üle. Tsiteerin ERRile intervjuu andnud politseinikku: «See ei ole normaalne, et sellised jõmikad tulevad, tümitavad ja nii ongi noh. Mingi tagajärg peab saabuma neile, [kes politseiametniku vastu kätt tõstavad].»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998158/madridis-protestisid-tuhanded-inimesed-karpemeetmete-vastu/</td>\n",
       "      <td>3</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>Hispaania peaminister Mariano Rajoy on Euroopa Liidu üha kasvava surve all, et ta vähendaks sel aastal eelarvepuudujääki 6,3 protsendini sisemajanduse koguproduktist (SKP), järgmisel aastal 4,5-ni ning 2014. aastal 2,8 protsendini. Kolme aastaga kavatseb valitsus hoida kokku 150 miljardit eurot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998158/madridis-protestisid-tuhanded-inimesed-karpemeetmete-vastu/</td>\n",
       "      <td>4</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>Hispaania keskpank on hoiatanud, et riik ei pruugi sel aastal eelarvepuudujääki kavandatud mahus vähendada ning võib libiseda järgmisel aastal sügavasse kriisi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/</td>\n",
       "      <td>1</td>\n",
       "      <td>neutraalne</td>\n",
       "      <td>Gruusia parlamendivalimised võitnud koalitsiooni Gruusia Unistus liider, tulevane peaminister Bidzina Ivanišvili teeb esmaspäeval pressikonverentsil teatavaks ministrikandidaadid, ütles ta pühapäeval Facebookis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/</td>\n",
       "      <td>2</td>\n",
       "      <td>neutraalne</td>\n",
       "      <td>Gruusia meedia on juba spekuleerinud tulevase valitsuse koosseisu üle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/</td>\n",
       "      <td>3</td>\n",
       "      <td>neutraalne</td>\n",
       "      <td>Arvatakse, et kaitseministriks saab Koba Davitašvili, siseministriks Irakli Alasanija, välisministriks Tedo Džaparidze, rahandusministriks Irakli Garibašvili, majandusarengu ministriks Nodar Haduri ja justiitsministriks Teja Tsulukiani.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3848 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rubric  \\\n",
       "0      ARVAMUS   \n",
       "1      ARVAMUS   \n",
       "2      ARVAMUS   \n",
       "3      ARVAMUS   \n",
       "4      ARVAMUS   \n",
       "...        ...   \n",
       "3843  VÄLISMAA   \n",
       "3844  VÄLISMAA   \n",
       "3845  VÄLISMAA   \n",
       "3846  VÄLISMAA   \n",
       "3847  VÄLISMAA   \n",
       "\n",
       "                                                                                             url  \\\n",
       "0                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "1                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "2                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "3                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "4                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "...                                                                                          ...   \n",
       "3843  http://www.postimees.ee/998158/madridis-protestisid-tuhanded-inimesed-karpemeetmete-vastu/   \n",
       "3844  http://www.postimees.ee/998158/madridis-protestisid-tuhanded-inimesed-karpemeetmete-vastu/   \n",
       "3845               http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/   \n",
       "3846               http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/   \n",
       "3847               http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/   \n",
       "\n",
       "     order     sentiment  \\\n",
       "0        1    negatiivne   \n",
       "1        2  vastuoluline   \n",
       "2        3    positiivne   \n",
       "3        4  vastuoluline   \n",
       "4        5    negatiivne   \n",
       "...    ...           ...   \n",
       "3843     3    negatiivne   \n",
       "3844     4    negatiivne   \n",
       "3845     1    neutraalne   \n",
       "3846     2    neutraalne   \n",
       "3847     3    neutraalne   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \n",
       "0                                                                                                            Enam kui kümme aastat tagasi tegutses huumorisaates «Wremja» inspektor Kukeke, kes kogu aeg vingus väikese palga pärast ja vaatas, mida saaks töö juurest koju tassida. Stsenaristid Andrus Kivirähk ja Mart Juur olid Kukekese isikusse kokku valanud kõik, mis 1990. aastate Eesti politseinikke halvast küljest iseloomustas.  \n",
       "1                            Neid ridu kirjutades tundub isegi ebaviisakas seda karikatuurset kuju meenutada. Juba saate eetrisse mineku ajal oli tegemist vaatega ajalukku. Politsei on vabanenud üleminekuajal parema puudumisel palgatud juhuseotsijatest. Samuti jõudis ühena esimestest politseijuhtideni arusaamine, et avalik kaeblemine palkade üle ei tule ühelegi organisatsioonile kasuks – kannatab maine ja raha juurde ei tule.  \n",
       "2                                                                                 Isiklikult kohtasin natukegi Kukekese moodi politseinikku viimati kaheksa aasta eest Lätis. Eranditult kõik viimase kümnendi kokkupuuted politseiametnikega on kinnitanud: vaatamata raskustele on Eesti riik suutnud korrakaitsjateks värvata inimesi, kes on arukad, kohusetundlikud, lugupidamist sisendavas füüsilises vormis ja hea väljendusoskusega.  \n",
       "3     Olen näinud ka, kuidas patrull korrarikkujat taltsutab, ning suur osa sellest seisnes enesekindlas olekus ning vastuvaidlemist välistavalt, kuid rahulikult antud korraldustes. Aprillirahutuste ajal veendusime, et Eesti politsei suudab käituda ründajatega väga karmilt. Vaevalt et mitmeks tunniks näoli porisele asfaldile pandud märatsejat lohutas, et kohus hiljem teda riigijuhtide lubatud viisil aastateks vangi ei pannud.  \n",
       "4                                                  Kummaline on nüüd äkki lugeda politsei ja siseministeeriumi ametnike kurtmist kohtu poolt politseinike ründajatele (lihtsalt öeldes – peksjatele) määratud karistuste üle. Tsiteerin ERRile intervjuu andnud politseinikku: «See ei ole normaalne, et sellised jõmikad tulevad, tümitavad ja nii ongi noh. Mingi tagajärg peab saabuma neile, [kes politseiametniku vastu kätt tõstavad].»  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
       "3843                                                                                                                                 Hispaania peaminister Mariano Rajoy on Euroopa Liidu üha kasvava surve all, et ta vähendaks sel aastal eelarvepuudujääki 6,3 protsendini sisemajanduse koguproduktist (SKP), järgmisel aastal 4,5-ni ning 2014. aastal 2,8 protsendini. Kolme aastaga kavatseb valitsus hoida kokku 150 miljardit eurot.  \n",
       "3844                                                                                                                                                                                                                                                                         Hispaania keskpank on hoiatanud, et riik ei pruugi sel aastal eelarvepuudujääki kavandatud mahus vähendada ning võib libiseda järgmisel aastal sügavasse kriisi.  \n",
       "3845                                                                                                                                                                                                                      Gruusia parlamendivalimised võitnud koalitsiooni Gruusia Unistus liider, tulevane peaminister Bidzina Ivanišvili teeb esmaspäeval pressikonverentsil teatavaks ministrikandidaadid, ütles ta pühapäeval Facebookis.  \n",
       "3846                                                                                                                                                                                                                                                                                                                                                                   Gruusia meedia on juba spekuleerinud tulevase valitsuse koosseisu üle.  \n",
       "3847                                                                                                                                                                                             Arvatakse, et kaitseministriks saab Koba Davitašvili, siseministriks Irakli Alasanija, välisministriks Tedo Džaparidze, rahandusministriks Irakli Garibašvili, majandusarengu ministriks Nodar Haduri ja justiitsministriks Teja Tsulukiani.  \n",
       "\n",
       "[3848 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "andmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3824e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "train, test = train_test_split(andmed, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.125)\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file = \"vocab_final.txt\", vocab_file_form = \"vocab_form.txt\", max_length = 128,\n",
    "                         padding = \"max_length\", truncation = True, return_tensors = \"pt\", mask_token=\"ˇMASKˇ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac731825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18.8 s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_encodings = tokenizer(list(train[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "train_dataset = Dataset.from_dict(train_encodings)\n",
    "\n",
    "val_encodings = tokenizer(list(val[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "val_dataset = Dataset.from_dict(val_encodings)\n",
    "\n",
    "test_encodings = tokenizer(list(test[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "test_dataset = Dataset.from_dict(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9094e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 05:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\Documents\\makatoo\\transformers\\src\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n",
      "  Number of trainable parameters = 160595620\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 04:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Lemma</th>\n",
       "      <th>Accuracy Vorm</th>\n",
       "      <th>N Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.386400</td>\n",
       "      <td>9.721108</td>\n",
       "      <td>0.194472</td>\n",
       "      <td>0.242843</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to MLM_results\\checkpoint-13\n",
      "Configuration saved in MLM_results\\checkpoint-13\\config.json\n",
      "Model weights saved in MLM_results\\checkpoint-13\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=12.3864499605619, metrics={'train_runtime': 263.4975, 'train_samples_per_second': 0.759, 'train_steps_per_second': 0.049, 'total_flos': 38150348390400.0, 'train_loss': 12.3864499605619, 'epoch': 1.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(\"train_results/checkpoint-100000\")\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions_lemma = np.argmax(predictions[0], axis = 2).ravel()\n",
    "    labels_lemma = [y[0] for x in labels for y in x]\n",
    "    predictions_vorm = np.argmax(predictions[1], axis = 2).ravel()\n",
    "    labels_vorm = [y[1] for x in labels for y in x]\n",
    "\n",
    "    final_pred_lemma = [(p,l) for p, l in zip(predictions_lemma, labels_lemma) if l > 4 and l != -100]\n",
    "    acc_lemma = sum(np.array([x[0] for x in final_pred_lemma]) == np.array([x[1] for x in final_pred_lemma]))/len(final_pred_lemma)\n",
    "\n",
    "    final_pred_vorm = [(p,l) for p, l in zip(predictions_vorm, labels_vorm) if l > 4 and l != -100]\n",
    "    acc_vorm = sum(np.array([x[0] for x in final_pred_vorm]) == np.array([x[1] for x in final_pred_vorm]))/len(final_pred_vorm)\n",
    "\n",
    "    return({'Accuracy_lemma' : acc_lemma, 'Accuracy_vorm' : acc_vorm, 'n_val' : len(final_pred_lemma)})\n",
    "    \n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=True,\n",
    "        mlm_probability=0.15\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"MLM_results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset, \n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "trainer.evaluate()\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b02de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy lemma : 0.2044790652385589\n",
      "Accuracy vorm : 0.24050632911392406\n",
      "n test : 1027\n"
     ]
    }
   ],
   "source": [
    "# Ennustuste tegemine\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "\n",
    "predictions_lemma = np.argmax(predictions[0], axis = 2).ravel()\n",
    "labels_lemma = [y[0] for x in labels for y in x]\n",
    "predictions_vorm = np.argmax(predictions[1], axis = 2).ravel()\n",
    "labels_vorm = [y[1] for x in labels for y in x]\n",
    "\n",
    "final_pred_lemma = [(p,l) for p, l in zip(predictions_lemma, labels_lemma) if l != -100]\n",
    "acc_lemma = sum(np.array([x[0] for x in final_pred_lemma]) == np.array([x[1] for x in final_pred_lemma]))/len(final_pred_lemma)\n",
    "\n",
    "final_pred_vorm = [(p,l) for p, l in zip(predictions_vorm, labels_vorm) if l != -100]\n",
    "acc_vorm = sum(np.array([x[0] for x in final_pred_vorm]) == np.array([x[1] for x in final_pred_vorm]))/len(final_pred_vorm)\n",
    "\n",
    "print(f\"Accuracy lemma : {acc_lemma}\")\n",
    "print(f\"Accuracy vorm : {acc_vorm}\")\n",
    "print(f\"n test : {len(final_pred_lemma)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6484af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ESTBERT ###\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tartuNLP/EstBERT\", max_length = 128,\n",
    "                         padding = \"max_length\", truncation = True, return_tensors = \"pt\")\n",
    "train_encodings = tokenizer(list(train[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "train_dataset = Dataset.from_dict(train_encodings)\n",
    "\n",
    "val_encodings = tokenizer(list(val[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "val_dataset = Dataset.from_dict(val_encodings)\n",
    "\n",
    "test_encodings = tokenizer(list(test[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "test_dataset = Dataset.from_dict(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e58203e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "C:\\Users\\rauln\\Documents\\makatoo\\transformers\\src\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n",
      "  Number of trainable parameters = 124492880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 04:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Mlm</th>\n",
       "      <th>N Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.446100</td>\n",
       "      <td>4.263000</td>\n",
       "      <td>0.368193</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to MLM_results_EST\\checkpoint-13\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=4.446066636305589, metrics={'train_runtime': 263.2578, 'train_samples_per_second': 0.76, 'train_steps_per_second': 0.049, 'total_flos': 13163232460800.0, 'train_loss': 4.446066636305589, 'epoch': 1.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"tartuNLP/EstBERT\")\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions_MLM = np.argmax(predictions, axis = 2).ravel()\n",
    "    labels_MLM = [y for x in labels for y in x]\n",
    "    final_pred = [(p,l) for p, l in zip(predictions_MLM, labels_MLM) if l != -100]\n",
    "    acc = sum(np.array([x[0] for x in final_pred]) == np.array([x[1] for x in final_pred]))/len(final_pred)\n",
    "\n",
    "    return({'Accuracy_MLM' : acc, 'n_val' : len(final_pred)})\n",
    "    \n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=True,\n",
    "        mlm_probability=0.15\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"MLM_results_EST\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset, \n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "#trainer.evaluate()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97bfc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy MLM : 0.3891525423728814\n",
      "n test : 1475\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "\n",
    "predictions_MLM = np.argmax(predictions, axis = 2).ravel()\n",
    "labels_MLM = [y for x in labels for y in x]\n",
    "final_pred = [(p,l) for p, l in zip(predictions_MLM, labels_MLM) if l != -100]\n",
    "acc = sum(np.array([x[0] for x in final_pred]) == np.array([x[1] for x in final_pred]))/len(final_pred)\n",
    "\n",
    "print(f\"Accuracy MLM : {acc}\")\n",
    "print(f\"n test : {len(final_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e764bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6698, 23062),\n",
       " (42, 16461),\n",
       " (1543, 31532),\n",
       " (19642, 31783),\n",
       " (46, 68),\n",
       " (49904, 42),\n",
       " (75, 11361),\n",
       " (251, 251),\n",
       " (405, 2120),\n",
       " (21869, 863),\n",
       " (135, 135),\n",
       " (40238, 40238),\n",
       " (17833, 37),\n",
       " (82, 37676),\n",
       " (6983, 20489),\n",
       " (3063, 3063),\n",
       " (3593, 1293),\n",
       " (3593, 3593),\n",
       " (1387, 39708),\n",
       " (34630, 12138),\n",
       " (5132, 5455),\n",
       " (32333, 6698),\n",
       " (49883, 49883),\n",
       " (42, 42),\n",
       " (15, 15),\n",
       " (5657, 5169),\n",
       " (251, 251),\n",
       " (13523, 3372),\n",
       " (280, 4894),\n",
       " (49883, 49883),\n",
       " (11, 11),\n",
       " (35784, 44183),\n",
       " (42, 3330),\n",
       " (49888, 91),\n",
       " (37, 157),\n",
       " (126, 126),\n",
       " (6455, 6455),\n",
       " (15, 429),\n",
       " (7477, 20887),\n",
       " (42, 3228),\n",
       " (137, 4842),\n",
       " (710, 710),\n",
       " (11, 11),\n",
       " (584, 4229),\n",
       " (19402, 1097),\n",
       " (20, 49889),\n",
       " (79, 6847),\n",
       " (97, 464),\n",
       " (1184, 1184),\n",
       " (24694, 194),\n",
       " (1036, 34090),\n",
       " (10, 49884),\n",
       " (37, 11),\n",
       " (29890, 34893),\n",
       " (37, 157),\n",
       " (42490, 42490),\n",
       " (37, 37),\n",
       " (49887, 49887),\n",
       " (5903, 2643),\n",
       " (24846, 8386),\n",
       " (21729, 21729),\n",
       " (7361, 2744),\n",
       " (11, 11),\n",
       " (90, 90),\n",
       " (308, 308),\n",
       " (832, 1966),\n",
       " (6917, 6917),\n",
       " (49883, 1733),\n",
       " (153, 153),\n",
       " (4780, 1249),\n",
       " (11, 11),\n",
       " (2691, 2691),\n",
       " (803, 803),\n",
       " (2691, 4062),\n",
       " (28358, 1104),\n",
       " (37, 37),\n",
       " (42, 11361),\n",
       " (2444, 35007),\n",
       " (49904, 49884),\n",
       " (37, 4887),\n",
       " (2878, 35007),\n",
       " (36, 10206),\n",
       " (97, 97),\n",
       " (5199, 740),\n",
       " (43, 43),\n",
       " (2248, 6698),\n",
       " (19113, 24322),\n",
       " (122, 531),\n",
       " (11, 37),\n",
       " (6036, 49887),\n",
       " (447, 3086),\n",
       " (447, 15),\n",
       " (6978, 19202),\n",
       " (15, 15),\n",
       " (16374, 16374),\n",
       " (2706, 1525),\n",
       " (1282, 848),\n",
       " (6036, 49887),\n",
       " (1200, 250),\n",
       " (15, 15),\n",
       " (1156, 1156),\n",
       " (10963, 10963),\n",
       " (35504, 34420),\n",
       " (470, 61),\n",
       " (208, 55),\n",
       " (45688, 45688),\n",
       " (101, 49892),\n",
       " (11, 6897),\n",
       " (15, 15),\n",
       " (20887, 14287),\n",
       " (159, 5460),\n",
       " (2696, 16310),\n",
       " (20558, 20558),\n",
       " (7650, 19230),\n",
       " (251, 935),\n",
       " (2443, 13498),\n",
       " (105, 10930),\n",
       " (470, 326),\n",
       " (3272, 1070),\n",
       " (42, 42),\n",
       " (79, 79),\n",
       " (10, 10),\n",
       " (1399, 1399),\n",
       " (417, 207),\n",
       " (417, 417),\n",
       " (16444, 16444),\n",
       " (7583, 11523),\n",
       " (2374, 1907),\n",
       " (8, 61),\n",
       " (11, 15),\n",
       " (1845, 1845),\n",
       " (42, 3665),\n",
       " (3324, 3324),\n",
       " (49892, 688),\n",
       " (49883, 11896),\n",
       " (37396, 1919),\n",
       " (137, 137),\n",
       " (1901, 14372),\n",
       " (31365, 41),\n",
       " (158, 158),\n",
       " (2416, 13284),\n",
       " (241, 368),\n",
       " (40593, 40593),\n",
       " (15, 15),\n",
       " (42, 42),\n",
       " (6144, 4591),\n",
       " (49885, 49885),\n",
       " (2362, 13555),\n",
       " (5094, 5094),\n",
       " (15248, 10639),\n",
       " (42, 42),\n",
       " (131, 490),\n",
       " (3414, 30043),\n",
       " (903, 23),\n",
       " (4593, 1611),\n",
       " (23, 23),\n",
       " (15, 15),\n",
       " (8713, 14632),\n",
       " (15, 15),\n",
       " (3325, 1026),\n",
       " (396, 62),\n",
       " (13818, 2931),\n",
       " (37529, 28598),\n",
       " (1543, 1543),\n",
       " (15, 15),\n",
       " (41, 499),\n",
       " (79, 31252),\n",
       " (49885, 1948),\n",
       " (2414, 2414),\n",
       " (24060, 179),\n",
       " (700, 20881),\n",
       " (49885, 65),\n",
       " (871, 871),\n",
       " (42, 42),\n",
       " (11, 11),\n",
       " (193, 193),\n",
       " (74, 74),\n",
       " (49887, 49887),\n",
       " (458, 15355),\n",
       " (2283, 10990),\n",
       " (13244, 13244),\n",
       " (863, 676),\n",
       " (3355, 1254),\n",
       " (478, 478),\n",
       " (42, 6827),\n",
       " (2448, 12846),\n",
       " (465, 5962),\n",
       " (49885, 10487),\n",
       " (37676, 15222),\n",
       " (733, 1074),\n",
       " (25244, 37581),\n",
       " (49890, 49890),\n",
       " (32946, 42857),\n",
       " (15, 15),\n",
       " (94, 922),\n",
       " (143, 943),\n",
       " (464, 15),\n",
       " (15, 15),\n",
       " (1380, 1380),\n",
       " (6399, 733),\n",
       " (20012, 20012),\n",
       " (1358, 833),\n",
       " (2084, 2084),\n",
       " (5647, 18942),\n",
       " (79, 1299),\n",
       " (82, 82),\n",
       " (5647, 863),\n",
       " (36, 36),\n",
       " (9756, 9756),\n",
       " (452, 452),\n",
       " (12026, 19505),\n",
       " (145, 42),\n",
       " (73, 156),\n",
       " (296, 296),\n",
       " (16, 16),\n",
       " (19642, 246),\n",
       " (49892, 352),\n",
       " (94, 94),\n",
       " (97, 97),\n",
       " (1079, 1079),\n",
       " (689, 709),\n",
       " (6071, 1990),\n",
       " (768, 598),\n",
       " (2310, 2310),\n",
       " (598, 4805),\n",
       " (4508, 1211),\n",
       " (36, 36),\n",
       " (47693, 47693),\n",
       " (15, 15),\n",
       " (1851, 23050),\n",
       " (49882, 8682),\n",
       " (74, 572),\n",
       " (3116, 1016),\n",
       " (2239, 2239),\n",
       " (4593, 18010),\n",
       " (11, 11),\n",
       " (172, 3979),\n",
       " (49882, 43),\n",
       " (49889, 49883),\n",
       " (49889, 6777),\n",
       " (5780, 5780),\n",
       " (3844, 3844),\n",
       " (15, 15),\n",
       " (36509, 15469),\n",
       " (11, 8943),\n",
       " (34090, 104),\n",
       " (20190, 3751),\n",
       " (193, 523),\n",
       " (28426, 25240),\n",
       " (803, 36),\n",
       " (287, 66),\n",
       " (21667, 48690),\n",
       " (74, 74),\n",
       " (286, 286),\n",
       " (11931, 6917),\n",
       " (580, 4067),\n",
       " (1779, 580),\n",
       " (1384, 140),\n",
       " (86, 173),\n",
       " (173, 173),\n",
       " (4163, 4163),\n",
       " (16860, 45560),\n",
       " (381, 11566),\n",
       " (250, 602),\n",
       " (37, 37),\n",
       " (31, 6945),\n",
       " (36157, 2391),\n",
       " (11, 11),\n",
       " (49886, 49886),\n",
       " (29146, 9420),\n",
       " (25177, 2691),\n",
       " (1659, 8878),\n",
       " (40799, 293),\n",
       " (1492, 5317),\n",
       " (10, 179),\n",
       " (1811, 10),\n",
       " (10, 11),\n",
       " (10, 74),\n",
       " (82, 49893),\n",
       " (1147, 4625),\n",
       " (9420, 8411),\n",
       " (443, 69),\n",
       " (319, 319),\n",
       " (49887, 32404),\n",
       " (882, 2237),\n",
       " (1092, 1318),\n",
       " (1249, 251),\n",
       " (14490, 14490),\n",
       " (703, 330),\n",
       " (37, 3704),\n",
       " (2908, 2908),\n",
       " (126, 614),\n",
       " (49885, 28056),\n",
       " (49890, 613),\n",
       " (301, 301),\n",
       " (179, 179),\n",
       " (6917, 1016),\n",
       " (2154, 3011),\n",
       " (15316, 15316),\n",
       " (42, 42),\n",
       " (1719, 4769),\n",
       " (34151, 295),\n",
       " (211, 4067),\n",
       " (19402, 41627),\n",
       " (97, 1935),\n",
       " (15, 15),\n",
       " (158, 15),\n",
       " (15, 15),\n",
       " (211, 416),\n",
       " (259, 5821),\n",
       " (946, 1876),\n",
       " (1249, 1249),\n",
       " (1249, 1249),\n",
       " (49887, 49887),\n",
       " (1668, 1668),\n",
       " (49883, 49885),\n",
       " (137, 4971),\n",
       " (1314, 29829),\n",
       " (3163, 1166),\n",
       " (684, 667),\n",
       " (42, 42),\n",
       " (532, 49886),\n",
       " (121, 32591),\n",
       " (74, 74),\n",
       " (15, 15),\n",
       " (20887, 39707),\n",
       " (15, 93),\n",
       " (42, 42),\n",
       " (140, 3772),\n",
       " (1160, 8157),\n",
       " (37, 24846),\n",
       " (49887, 1171),\n",
       " (800, 45176),\n",
       " (15, 15),\n",
       " (1402, 21190),\n",
       " (26201, 2510),\n",
       " (16312, 602),\n",
       " (22427, 22427),\n",
       " (22427, 22427),\n",
       " (42, 42),\n",
       " (58, 58),\n",
       " (331, 11361),\n",
       " (30603, 21627),\n",
       " (49883, 49883),\n",
       " (37, 37),\n",
       " (11, 11),\n",
       " (11, 37),\n",
       " (6698, 31475),\n",
       " (66, 39631),\n",
       " (452, 47946),\n",
       " (46, 105),\n",
       " (2652, 2652),\n",
       " (434, 434),\n",
       " (11, 11),\n",
       " (42, 145),\n",
       " (1016, 4390),\n",
       " (49887, 41),\n",
       " (251, 1042),\n",
       " (9420, 13641),\n",
       " (172, 1436),\n",
       " (26152, 683),\n",
       " (74, 74),\n",
       " (126, 126),\n",
       " (15, 11),\n",
       " (603, 22857),\n",
       " (2991, 2991),\n",
       " (82, 82),\n",
       " (15, 15),\n",
       " (97, 97),\n",
       " (97, 613),\n",
       " (11, 613),\n",
       " (11, 5566),\n",
       " (613, 613),\n",
       " (2152, 10265),\n",
       " (633, 633),\n",
       " (41, 41),\n",
       " (1076, 1853),\n",
       " (553, 1601),\n",
       " (676, 676),\n",
       " (670, 670),\n",
       " (703, 683),\n",
       " (10, 49886),\n",
       " (11, 11),\n",
       " (5393, 6414),\n",
       " (11, 65),\n",
       " (6416, 19002),\n",
       " (15, 49904),\n",
       " (4707, 35217),\n",
       " (49937, 740),\n",
       " (49141, 5289),\n",
       " (42, 42),\n",
       " (205, 1572),\n",
       " (882, 36908),\n",
       " (25, 25),\n",
       " (11, 11),\n",
       " (126, 212),\n",
       " (1363, 920),\n",
       " (79, 79),\n",
       " (13399, 2708),\n",
       " (11, 11),\n",
       " (55, 129),\n",
       " (28, 28),\n",
       " (287, 3599),\n",
       " (66, 1637),\n",
       " (1554, 13933),\n",
       " (2666, 172),\n",
       " (179, 1572),\n",
       " (49887, 10210),\n",
       " (569, 31475),\n",
       " (8, 1036),\n",
       " (434, 1613),\n",
       " (74, 74),\n",
       " (9380, 245),\n",
       " (42, 42),\n",
       " (49887, 49887),\n",
       " (10576, 10576),\n",
       " (3704, 3704),\n",
       " (41, 28773),\n",
       " (7850, 16),\n",
       " (49886, 28048),\n",
       " (882, 521),\n",
       " (4568, 11172),\n",
       " (2032, 19868),\n",
       " (22439, 3814),\n",
       " (15, 15),\n",
       " (18490, 18490),\n",
       " (3696, 3956),\n",
       " (1478, 49883),\n",
       " (74, 179),\n",
       " (15, 15),\n",
       " (15, 8449),\n",
       " (117, 117),\n",
       " (42, 385),\n",
       " (42, 42),\n",
       " (676, 953),\n",
       " (37816, 8596),\n",
       " (31, 25),\n",
       " (15, 49883),\n",
       " (140, 140),\n",
       " (290, 857),\n",
       " (7946, 3611),\n",
       " (15657, 15657),\n",
       " (179, 179),\n",
       " (31260, 13757),\n",
       " (454, 1249),\n",
       " (49885, 11),\n",
       " (15, 15),\n",
       " (20030, 1022),\n",
       " (16738, 32404),\n",
       " (248, 14153),\n",
       " (6738, 9861),\n",
       " (1543, 2310),\n",
       " (11, 15),\n",
       " (42, 1509),\n",
       " (2033, 8278),\n",
       " (553, 2984),\n",
       " (15, 15),\n",
       " (86, 11381),\n",
       " (10, 49882),\n",
       " (33757, 33757),\n",
       " (52, 52),\n",
       " (1771, 8005),\n",
       " (251, 251),\n",
       " (1996, 1996),\n",
       " (30907, 30907),\n",
       " (4944, 4944),\n",
       " (46521, 46521),\n",
       " (37, 20887),\n",
       " (2870, 145),\n",
       " (368, 30845),\n",
       " (49885, 49885),\n",
       " (12045, 7416),\n",
       " (9101, 703),\n",
       " (14834, 14834),\n",
       " (523, 3563),\n",
       " (11, 130),\n",
       " (37, 37),\n",
       " (12045, 12045),\n",
       " (5535, 5535),\n",
       " (2586, 49887),\n",
       " (49886, 4560),\n",
       " (738, 13253),\n",
       " (7812, 9062),\n",
       " (41660, 127),\n",
       " (49887, 1148),\n",
       " (584, 584),\n",
       " (40494, 326),\n",
       " (19642, 41713),\n",
       " (49892, 49892),\n",
       " (15, 15),\n",
       " (32748, 32748),\n",
       " (49885, 1010),\n",
       " (258, 258),\n",
       " (20887, 24121),\n",
       " (32404, 32404),\n",
       " (82, 82),\n",
       " (396, 396),\n",
       " (11, 11),\n",
       " (140, 140),\n",
       " (49882, 20558),\n",
       " (49937, 4293),\n",
       " (19642, 81),\n",
       " (28, 5895),\n",
       " (2354, 3605),\n",
       " (11, 11),\n",
       " (65, 65),\n",
       " (11576, 45692),\n",
       " (49904, 49904),\n",
       " (118, 118),\n",
       " (4637, 23564),\n",
       " (326, 326),\n",
       " (241, 241),\n",
       " (12166, 2313),\n",
       " (3732, 1679),\n",
       " (27005, 27005),\n",
       " (42, 42),\n",
       " (508, 508),\n",
       " (9000, 13096),\n",
       " (8656, 20261),\n",
       " (49885, 882),\n",
       " (37, 1764),\n",
       " (3518, 5075),\n",
       " (11, 11),\n",
       " (1572, 3982),\n",
       " (25097, 25097),\n",
       " (74, 74),\n",
       " (44, 44),\n",
       " (1438, 1438),\n",
       " (23, 49892),\n",
       " (5466, 346),\n",
       " (49888, 49884),\n",
       " (145, 145),\n",
       " (31475, 13444),\n",
       " (8, 657),\n",
       " (5876, 5876),\n",
       " (15, 15),\n",
       " (8264, 9906),\n",
       " (4508, 2973),\n",
       " (934, 4519),\n",
       " (42, 9409),\n",
       " (15, 15),\n",
       " (775, 364),\n",
       " (74, 74),\n",
       " (4642, 899),\n",
       " (140, 5776),\n",
       " (882, 503),\n",
       " (4359, 49886),\n",
       " (17721, 383),\n",
       " (8, 21876),\n",
       " (981, 15285),\n",
       " (1358, 835),\n",
       " (42, 3367),\n",
       " (41, 143),\n",
       " (82, 1245),\n",
       " (97, 1962),\n",
       " (11, 43161),\n",
       " (705, 3655),\n",
       " (3629, 3629),\n",
       " (20709, 20709),\n",
       " (5549, 5549),\n",
       " (1299, 633),\n",
       " (1855, 14240),\n",
       " (981, 981),\n",
       " (3547, 3547),\n",
       " (6891, 676),\n",
       " (404, 10094),\n",
       " (40405, 710),\n",
       " (43, 3264),\n",
       " (35578, 35578),\n",
       " (5026, 19446),\n",
       " (4484, 16111),\n",
       " (49884, 47),\n",
       " (11, 11),\n",
       " (174, 174),\n",
       " (86, 86),\n",
       " (15, 15),\n",
       " (42, 42),\n",
       " (11, 11),\n",
       " (126, 9663),\n",
       " (727, 727),\n",
       " (6302, 4913),\n",
       " (98, 1562),\n",
       " (1078, 1078),\n",
       " (861, 861),\n",
       " (13326, 13326),\n",
       " (1078, 1078),\n",
       " (368, 5628),\n",
       " (3783, 1581),\n",
       " (49883, 45107),\n",
       " (119, 94),\n",
       " (41, 41),\n",
       " (143, 126),\n",
       " (920, 19642),\n",
       " (49904, 49904),\n",
       " (37, 37),\n",
       " (8216, 4707),\n",
       " (35, 35),\n",
       " (42, 42),\n",
       " (2595, 27399),\n",
       " (22634, 6698),\n",
       " (1080, 470),\n",
       " (819, 5056),\n",
       " (2202, 16196),\n",
       " (13444, 40526),\n",
       " (1188, 1188),\n",
       " (258, 258),\n",
       " (43110, 1709),\n",
       " (159, 159),\n",
       " (48487, 4894),\n",
       " (95, 37357),\n",
       " (2156, 2156),\n",
       " (15, 15),\n",
       " (49885, 2239),\n",
       " (8, 8),\n",
       " (37, 37),\n",
       " (49892, 29285),\n",
       " (82, 82),\n",
       " (55, 55),\n",
       " (1358, 27374),\n",
       " (41, 1084),\n",
       " (3495, 3495),\n",
       " (49884, 231),\n",
       " (251, 11926),\n",
       " (82, 1492),\n",
       " (405, 1639),\n",
       " (61, 37),\n",
       " (3068, 22546),\n",
       " (4894, 9622),\n",
       " (9170, 9170),\n",
       " (38704, 38704),\n",
       " (4565, 2040),\n",
       " (29066, 1249),\n",
       " (49679, 5445),\n",
       " (6478, 39598),\n",
       " (6640, 6640),\n",
       " (15, 15),\n",
       " (8440, 973),\n",
       " (173, 173),\n",
       " (37, 37),\n",
       " (10087, 10087),\n",
       " (74, 74),\n",
       " (97, 97),\n",
       " (895, 1041),\n",
       " (159, 159),\n",
       " (414, 3286),\n",
       " (6552, 5570),\n",
       " (773, 773),\n",
       " (41844, 41844),\n",
       " (4352, 46242),\n",
       " (32496, 42586),\n",
       " (82, 27005),\n",
       " (29059, 3806),\n",
       " (97, 1515),\n",
       " (42, 42),\n",
       " (49904, 6040),\n",
       " (9950, 143),\n",
       " (1554, 4219),\n",
       " (6079, 6079),\n",
       " (49892, 49892),\n",
       " (15, 15),\n",
       " (145, 145),\n",
       " (5199, 1026),\n",
       " (49887, 49887),\n",
       " (9950, 9950),\n",
       " (49884, 33520),\n",
       " (41, 41),\n",
       " (42, 37),\n",
       " (20739, 20739),\n",
       " (121, 1595),\n",
       " (1362, 4412),\n",
       " (49884, 251),\n",
       " (49884, 1659),\n",
       " (49888, 49888),\n",
       " (20887, 20887),\n",
       " (97, 97),\n",
       " (32404, 1016),\n",
       " (49882, 521),\n",
       " (746, 2074),\n",
       " (553, 553),\n",
       " (15, 15),\n",
       " (37, 49890),\n",
       " (4707, 25816),\n",
       " (800, 800),\n",
       " (49885, 49885),\n",
       " (4551, 41544),\n",
       " (16381, 3386),\n",
       " (49895, 49895),\n",
       " (29790, 16273),\n",
       " (19198, 1877),\n",
       " (3040, 9032),\n",
       " (2673, 153),\n",
       " (37, 39467),\n",
       " (61, 49),\n",
       " (37, 49883),\n",
       " (259, 1249),\n",
       " (3897, 3897),\n",
       " (29308, 29308),\n",
       " (49883, 49883),\n",
       " (23967, 40050),\n",
       " (25558, 6771),\n",
       " (4707, 29416),\n",
       " (49885, 1817),\n",
       " (833, 835),\n",
       " (74, 560),\n",
       " (12121, 12121),\n",
       " (11, 560),\n",
       " (1, 2655),\n",
       " (543, 543),\n",
       " (468, 41279),\n",
       " (49885, 14458),\n",
       " (49885, 39),\n",
       " (37, 43670),\n",
       " (8, 8),\n",
       " (8, 1767),\n",
       " (15, 36616),\n",
       " (37947, 15),\n",
       " (2207, 2207),\n",
       " (174, 654),\n",
       " (25471, 2213),\n",
       " (1699, 55),\n",
       " (15, 15),\n",
       " (720, 720),\n",
       " (17853, 17853),\n",
       " (25105, 2021),\n",
       " (2542, 7257),\n",
       " (42, 42),\n",
       " (14324, 19731),\n",
       " (49885, 49884),\n",
       " (579, 579),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (11, 11),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (296, 19817),\n",
       " (8216, 9098),\n",
       " (580, 8),\n",
       " (7510, 49888),\n",
       " (16860, 42),\n",
       " (19446, 32),\n",
       " (86, 502),\n",
       " (533, 4302),\n",
       " (424, 424),\n",
       " (20887, 2840),\n",
       " (15, 580),\n",
       " (15, 15),\n",
       " (42, 49890),\n",
       " (229, 15),\n",
       " (26195, 816),\n",
       " (45754, 3216),\n",
       " (20887, 20887),\n",
       " (15, 15),\n",
       " (42, 97),\n",
       " (159, 159),\n",
       " (3142, 20914),\n",
       " (490, 490),\n",
       " (15, 15),\n",
       " (346, 8938),\n",
       " (9, 319),\n",
       " (579, 5413),\n",
       " (82, 82),\n",
       " (434, 2127),\n",
       " (11, 11),\n",
       " (458, 143),\n",
       " (14519, 14731),\n",
       " (103, 12349),\n",
       " (15, 49888),\n",
       " (49892, 2840),\n",
       " (251, 49885),\n",
       " (41, 41),\n",
       " (1055, 39631),\n",
       " (118, 118),\n",
       " (1248, 4123),\n",
       " (193, 193),\n",
       " (16205, 16205),\n",
       " (49904, 20355),\n",
       " (41, 34914),\n",
       " (278, 1285),\n",
       " (24576, 4006),\n",
       " (205, 205),\n",
       " (703, 703),\n",
       " (438, 438),\n",
       " (442, 442),\n",
       " (17240, 94),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (514, 514),\n",
       " (21812, 18074),\n",
       " (42, 145),\n",
       " (42, 42),\n",
       " (42, 3655),\n",
       " (2081, 2643),\n",
       " (499, 35216),\n",
       " (310, 310),\n",
       " (13865, 13865),\n",
       " (584, 15310),\n",
       " (37, 37),\n",
       " (42, 42),\n",
       " (1501, 9186),\n",
       " (3534, 3534),\n",
       " (18938, 22427),\n",
       " (3116, 4707),\n",
       " (11, 11),\n",
       " (105, 47678),\n",
       " (241, 241),\n",
       " (852, 852),\n",
       " (49886, 49886),\n",
       " (1249, 1249),\n",
       " (21244, 684),\n",
       " (20887, 20887),\n",
       " (563, 563),\n",
       " (15, 15),\n",
       " (862, 862),\n",
       " (87, 645),\n",
       " (751, 19413),\n",
       " (33, 2729),\n",
       " (3818, 1297),\n",
       " (404, 26195),\n",
       " (168, 8),\n",
       " (49882, 49882),\n",
       " (491, 2433),\n",
       " (49888, 18281),\n",
       " (687, 2845),\n",
       " (1595, 41660),\n",
       " (1623, 409),\n",
       " (4897, 4897),\n",
       " (6923, 16860),\n",
       " (11, 11),\n",
       " (79, 97),\n",
       " (49904, 121),\n",
       " (241, 364),\n",
       " (15, 49892),\n",
       " (48352, 6698),\n",
       " (331, 11361),\n",
       " (3421, 12284),\n",
       " (13359, 3299),\n",
       " (782, 782),\n",
       " (49887, 208),\n",
       " (478, 168),\n",
       " (596, 46),\n",
       " (1200, 1200),\n",
       " (22936, 22936),\n",
       " (1876, 11105),\n",
       " (153, 153),\n",
       " (15, 429),\n",
       " (15, 15),\n",
       " (15, 766),\n",
       " (49886, 857),\n",
       " (82, 82),\n",
       " (11, 37),\n",
       " (37, 16221),\n",
       " (23, 5503),\n",
       " (10226, 14700),\n",
       " (15, 15),\n",
       " (523, 523),\n",
       " (49886, 49883),\n",
       " (74, 229),\n",
       " (17111, 17111),\n",
       " (101, 101),\n",
       " (10193, 10193),\n",
       " (1046, 11141),\n",
       " (15, 15),\n",
       " (563, 563),\n",
       " (259, 339),\n",
       " (11500, 3496),\n",
       " (15, 15),\n",
       " (323, 1244),\n",
       " (895, 955),\n",
       " (158, 4114),\n",
       " (158, 158),\n",
       " (25244, 37581),\n",
       " (11, 3332),\n",
       " (15, 11),\n",
       " (1524, 8601),\n",
       " (825, 3806),\n",
       " (477, 32645),\n",
       " (34065, 34065),\n",
       " (703, 703),\n",
       " (347, 14834),\n",
       " (1506, 7237),\n",
       " (49885, 49885),\n",
       " (1947, 3419),\n",
       " (328, 32404),\n",
       " (39533, 1016),\n",
       " (37, 157),\n",
       " (15, 15),\n",
       " (94, 94),\n",
       " (34077, 48665),\n",
       " (74, 74),\n",
       " (11, 11),\n",
       " (42, 42),\n",
       " (273, 273),\n",
       " (887, 887),\n",
       " (1607, 3216),\n",
       " (11, 11),\n",
       " (79, 49886),\n",
       " (82, 82),\n",
       " (49904, 49904),\n",
       " (3593, 12069),\n",
       " (42, 462),\n",
       " (49893, 73),\n",
       " (229, 396),\n",
       " (97, 97),\n",
       " (82, 82),\n",
       " (118, 210),\n",
       " (1147, 16281),\n",
       " (16592, 1492),\n",
       " (140, 140),\n",
       " (320, 320),\n",
       " (179, 230),\n",
       " (61, 1084),\n",
       " (74, 74),\n",
       " (981, 2152),\n",
       " (31099, 6713),\n",
       " (1124, 30096),\n",
       " (16920, 16920),\n",
       " (10513, 8852),\n",
       " (42, 42),\n",
       " (8332, 19224),\n",
       " (7122, 10988),\n",
       " (1822, 1822),\n",
       " (40494, 6698),\n",
       " (6631, 6398),\n",
       " (3169, 3169),\n",
       " (1080, 1080),\n",
       " (20887, 21292),\n",
       " (12895, 12895),\n",
       " (5199, 5199),\n",
       " (41, 339),\n",
       " (23, 130),\n",
       " (178, 178),\n",
       " (10835, 4876),\n",
       " (49887, 36),\n",
       " (3721, 40300),\n",
       " (15, 15),\n",
       " (82, 49884),\n",
       " (591, 2124),\n",
       " (28878, 28878),\n",
       " (7478, 40300),\n",
       " (23, 23),\n",
       " (3603, 2931),\n",
       " (514, 10),\n",
       " (15, 15),\n",
       " (7325, 511),\n",
       " (6835, 6835),\n",
       " (34734, 16424),\n",
       " (4936, 4936),\n",
       " (2036, 2036),\n",
       " (43049, 43049),\n",
       " (37, 37),\n",
       " (6698, 126),\n",
       " (13628, 13628),\n",
       " (1080, 1080),\n",
       " (13451, 13451),\n",
       " (788, 11406),\n",
       " (18860, 43049),\n",
       " (122, 118),\n",
       " (159, 14830),\n",
       " (13762, 49886),\n",
       " (42, 2414),\n",
       " (259, 1249),\n",
       " (41, 434),\n",
       " (7534, 6242),\n",
       " (15, 15),\n",
       " (97, 97),\n",
       " (23, 23),\n",
       " (49883, 2289),\n",
       " (20649, 13757),\n",
       " (6698, 2666),\n",
       " (27868, 27868),\n",
       " (74, 74),\n",
       " (15, 15),\n",
       " (882, 127),\n",
       " (11417, 40737),\n",
       " (126, 523),\n",
       " (9672, 364),\n",
       " (7916, 6635),\n",
       " (15, 15),\n",
       " (11, 11),\n",
       " (1249, 39708),\n",
       " (37676, 37676),\n",
       " (15, 273),\n",
       " (447, 447),\n",
       " (49883, 50),\n",
       " (49889, 49887),\n",
       " (4331, 3892),\n",
       " (9, 1810),\n",
       " (213, 213),\n",
       " (368, 368),\n",
       " (19709, 39921),\n",
       " (409, 4254),\n",
       " (49937, 1249),\n",
       " (49, 30201),\n",
       " (95, 95),\n",
       " (32404, 236),\n",
       " (61, 168),\n",
       " (10085, 11615),\n",
       " (11, 11),\n",
       " (572, 572),\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
