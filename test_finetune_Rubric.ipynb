{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5054b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.transformers import BertTokenizer, BertForSequenceClassification,Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e08dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "andmed = pd.read_csv(\"Rubric_data/estonianvalence.csv\", encoding = \"utf8\", on_bad_lines='skip', header = None, \n",
    "                     names = [\"rubric\",\"url\", \"order\", \"sentiment\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9207c55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rubric</th>\n",
       "      <th>url</th>\n",
       "      <th>order</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>rubric_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>1</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>Enam kui kümme aastat tagasi tegutses huumorisaates «Wremja» inspektor Kukeke, kes kogu aeg vingus väikese palga pärast ja vaatas, mida saaks töö juurest koju tassida. Stsenaristid Andrus Kivirähk ja Mart Juur olid Kukekese isikusse kokku valanud kõik, mis 1990. aastate Eesti politseinikke halvast küljest iseloomustas.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>2</td>\n",
       "      <td>vastuoluline</td>\n",
       "      <td>Neid ridu kirjutades tundub isegi ebaviisakas seda karikatuurset kuju meenutada. Juba saate eetrisse mineku ajal oli tegemist vaatega ajalukku. Politsei on vabanenud üleminekuajal parema puudumisel palgatud juhuseotsijatest. Samuti jõudis ühena esimestest politseijuhtideni arusaamine, et avalik kaeblemine palkade üle ei tule ühelegi organisatsioonile kasuks – kannatab maine ja raha juurde ei tule.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>3</td>\n",
       "      <td>positiivne</td>\n",
       "      <td>Isiklikult kohtasin natukegi Kukekese moodi politseinikku viimati kaheksa aasta eest Lätis. Eranditult kõik viimase kümnendi kokkupuuted politseiametnikega on kinnitanud: vaatamata raskustele on Eesti riik suutnud korrakaitsjateks värvata inimesi, kes on arukad, kohusetundlikud, lugupidamist sisendavas füüsilises vormis ja hea väljendusoskusega.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>4</td>\n",
       "      <td>vastuoluline</td>\n",
       "      <td>Olen näinud ka, kuidas patrull korrarikkujat taltsutab, ning suur osa sellest seisnes enesekindlas olekus ning vastuvaidlemist välistavalt, kuid rahulikult antud korraldustes. Aprillirahutuste ajal veendusime, et Eesti politsei suudab käituda ründajatega väga karmilt. Vaevalt et mitmeks tunniks näoli porisele asfaldile pandud märatsejat lohutas, et kohus hiljem teda riigijuhtide lubatud viisil aastateks vangi ei pannud.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/</td>\n",
       "      <td>5</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>Kummaline on nüüd äkki lugeda politsei ja siseministeeriumi ametnike kurtmist kohtu poolt politseinike ründajatele (lihtsalt öeldes – peksjatele) määratud karistuste üle. Tsiteerin ERRile intervjuu andnud politseinikku: «See ei ole normaalne, et sellised jõmikad tulevad, tümitavad ja nii ongi noh. Mingi tagajärg peab saabuma neile, [kes politseiametniku vastu kätt tõstavad].»</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998158/madridis-protestisid-tuhanded-inimesed-karpemeetmete-vastu/</td>\n",
       "      <td>3</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>Hispaania peaminister Mariano Rajoy on Euroopa Liidu üha kasvava surve all, et ta vähendaks sel aastal eelarvepuudujääki 6,3 protsendini sisemajanduse koguproduktist (SKP), järgmisel aastal 4,5-ni ning 2014. aastal 2,8 protsendini. Kolme aastaga kavatseb valitsus hoida kokku 150 miljardit eurot.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998158/madridis-protestisid-tuhanded-inimesed-karpemeetmete-vastu/</td>\n",
       "      <td>4</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>Hispaania keskpank on hoiatanud, et riik ei pruugi sel aastal eelarvepuudujääki kavandatud mahus vähendada ning võib libiseda järgmisel aastal sügavasse kriisi.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/</td>\n",
       "      <td>1</td>\n",
       "      <td>neutraalne</td>\n",
       "      <td>Gruusia parlamendivalimised võitnud koalitsiooni Gruusia Unistus liider, tulevane peaminister Bidzina Ivanišvili teeb esmaspäeval pressikonverentsil teatavaks ministrikandidaadid, ütles ta pühapäeval Facebookis.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/</td>\n",
       "      <td>2</td>\n",
       "      <td>neutraalne</td>\n",
       "      <td>Gruusia meedia on juba spekuleerinud tulevase valitsuse koosseisu üle.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>VÄLISMAA</td>\n",
       "      <td>http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/</td>\n",
       "      <td>3</td>\n",
       "      <td>neutraalne</td>\n",
       "      <td>Arvatakse, et kaitseministriks saab Koba Davitašvili, siseministriks Irakli Alasanija, välisministriks Tedo Džaparidze, rahandusministriks Irakli Garibašvili, majandusarengu ministriks Nodar Haduri ja justiitsministriks Teja Tsulukiani.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3848 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rubric  \\\n",
       "0      ARVAMUS   \n",
       "1      ARVAMUS   \n",
       "2      ARVAMUS   \n",
       "3      ARVAMUS   \n",
       "4      ARVAMUS   \n",
       "...        ...   \n",
       "3843  VÄLISMAA   \n",
       "3844  VÄLISMAA   \n",
       "3845  VÄLISMAA   \n",
       "3846  VÄLISMAA   \n",
       "3847  VÄLISMAA   \n",
       "\n",
       "                                                                                             url  \\\n",
       "0                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "1                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "2                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "3                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "4                 http://arvamus.postimees.ee/1001520/anvar-samost-tahan-politseile-kindel-olla/   \n",
       "...                                                                                          ...   \n",
       "3843  http://www.postimees.ee/998158/madridis-protestisid-tuhanded-inimesed-karpemeetmete-vastu/   \n",
       "3844  http://www.postimees.ee/998158/madridis-protestisid-tuhanded-inimesed-karpemeetmete-vastu/   \n",
       "3845               http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/   \n",
       "3846               http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/   \n",
       "3847               http://www.postimees.ee/998270/ivanisvili-teeb-teatavaks-ministrikandidaadid/   \n",
       "\n",
       "     order     sentiment  \\\n",
       "0        1    negatiivne   \n",
       "1        2  vastuoluline   \n",
       "2        3    positiivne   \n",
       "3        4  vastuoluline   \n",
       "4        5    negatiivne   \n",
       "...    ...           ...   \n",
       "3843     3    negatiivne   \n",
       "3844     4    negatiivne   \n",
       "3845     1    neutraalne   \n",
       "3846     2    neutraalne   \n",
       "3847     3    neutraalne   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "0                                                                                                            Enam kui kümme aastat tagasi tegutses huumorisaates «Wremja» inspektor Kukeke, kes kogu aeg vingus väikese palga pärast ja vaatas, mida saaks töö juurest koju tassida. Stsenaristid Andrus Kivirähk ja Mart Juur olid Kukekese isikusse kokku valanud kõik, mis 1990. aastate Eesti politseinikke halvast küljest iseloomustas.   \n",
       "1                            Neid ridu kirjutades tundub isegi ebaviisakas seda karikatuurset kuju meenutada. Juba saate eetrisse mineku ajal oli tegemist vaatega ajalukku. Politsei on vabanenud üleminekuajal parema puudumisel palgatud juhuseotsijatest. Samuti jõudis ühena esimestest politseijuhtideni arusaamine, et avalik kaeblemine palkade üle ei tule ühelegi organisatsioonile kasuks – kannatab maine ja raha juurde ei tule.   \n",
       "2                                                                                 Isiklikult kohtasin natukegi Kukekese moodi politseinikku viimati kaheksa aasta eest Lätis. Eranditult kõik viimase kümnendi kokkupuuted politseiametnikega on kinnitanud: vaatamata raskustele on Eesti riik suutnud korrakaitsjateks värvata inimesi, kes on arukad, kohusetundlikud, lugupidamist sisendavas füüsilises vormis ja hea väljendusoskusega.   \n",
       "3     Olen näinud ka, kuidas patrull korrarikkujat taltsutab, ning suur osa sellest seisnes enesekindlas olekus ning vastuvaidlemist välistavalt, kuid rahulikult antud korraldustes. Aprillirahutuste ajal veendusime, et Eesti politsei suudab käituda ründajatega väga karmilt. Vaevalt et mitmeks tunniks näoli porisele asfaldile pandud märatsejat lohutas, et kohus hiljem teda riigijuhtide lubatud viisil aastateks vangi ei pannud.   \n",
       "4                                                  Kummaline on nüüd äkki lugeda politsei ja siseministeeriumi ametnike kurtmist kohtu poolt politseinike ründajatele (lihtsalt öeldes – peksjatele) määratud karistuste üle. Tsiteerin ERRile intervjuu andnud politseinikku: «See ei ole normaalne, et sellised jõmikad tulevad, tümitavad ja nii ongi noh. Mingi tagajärg peab saabuma neile, [kes politseiametniku vastu kätt tõstavad].»   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "3843                                                                                                                                 Hispaania peaminister Mariano Rajoy on Euroopa Liidu üha kasvava surve all, et ta vähendaks sel aastal eelarvepuudujääki 6,3 protsendini sisemajanduse koguproduktist (SKP), järgmisel aastal 4,5-ni ning 2014. aastal 2,8 protsendini. Kolme aastaga kavatseb valitsus hoida kokku 150 miljardit eurot.   \n",
       "3844                                                                                                                                                                                                                                                                         Hispaania keskpank on hoiatanud, et riik ei pruugi sel aastal eelarvepuudujääki kavandatud mahus vähendada ning võib libiseda järgmisel aastal sügavasse kriisi.   \n",
       "3845                                                                                                                                                                                                                      Gruusia parlamendivalimised võitnud koalitsiooni Gruusia Unistus liider, tulevane peaminister Bidzina Ivanišvili teeb esmaspäeval pressikonverentsil teatavaks ministrikandidaadid, ütles ta pühapäeval Facebookis.   \n",
       "3846                                                                                                                                                                                                                                                                                                                                                                   Gruusia meedia on juba spekuleerinud tulevase valitsuse koosseisu üle.   \n",
       "3847                                                                                                                                                                                             Arvatakse, et kaitseministriks saab Koba Davitašvili, siseministriks Irakli Alasanija, välisministriks Tedo Džaparidze, rahandusministriks Irakli Garibašvili, majandusarengu ministriks Nodar Haduri ja justiitsministriks Teja Tsulukiani.   \n",
       "\n",
       "      rubric_idx  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "3843           2  \n",
       "3844           2  \n",
       "3845           2  \n",
       "3846           2  \n",
       "3847           2  \n",
       "\n",
       "[3848 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "andmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9670c1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARVAMUS         972\n",
       "KOMM-P-EESTI    487\n",
       "KOMM-O-ELU      480\n",
       "EESTI           413\n",
       "SPORT           383\n",
       "ELU-O           329\n",
       "VÄLISMAA        313\n",
       "KULTUUR         262\n",
       "KRIMI           209\n",
       "Name: rubric, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "andmed.rubric.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3824e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Mappimine klasside indeksiteks ja tagasi\n",
    "rubriigid = list(set(andmed[\"rubric\"]))\n",
    "rubriik_idx = {tag:idx for idx, tag in enumerate(rubriigid)}\n",
    "idx_rubriik = {idx:tag for idx, tag in enumerate(rubriigid)}\n",
    "andmed[\"rubric_idx\"] = andmed[\"rubric\"].map(rubriik_idx)\n",
    "\n",
    "# Train 70%, Val 10%, Test 20%\n",
    "train, test = train_test_split(andmed, test_size=0.2, stratify=andmed[['rubric_idx']])\n",
    "train, val = train_test_split(train, test_size=0.125, stratify=train[['rubric_idx']])\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file = \"vocab_final.txt\", vocab_file_form = \"vocab_form.txt\", max_length = 128,\n",
    "                         padding = \"max_length\", truncation = True, return_tensors = \"pt\", mask_token=\"ˇMASKˇ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c65c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARVAMUS         680\n",
      "KOMM-P-EESTI    341\n",
      "KOMM-O-ELU      336\n",
      "EESTI           289\n",
      "SPORT           268\n",
      "ELU-O           230\n",
      "VÄLISMAA        219\n",
      "KULTUUR         184\n",
      "KRIMI           146\n",
      "Name: rubric, dtype: int64\n",
      "ARVAMUS         98\n",
      "KOMM-P-EESTI    49\n",
      "KOMM-O-ELU      48\n",
      "EESTI           41\n",
      "SPORT           38\n",
      "ELU-O           33\n",
      "VÄLISMAA        31\n",
      "KULTUUR         26\n",
      "KRIMI           21\n",
      "Name: rubric, dtype: int64\n",
      "ARVAMUS         194\n",
      "KOMM-P-EESTI     97\n",
      "KOMM-O-ELU       96\n",
      "EESTI            83\n",
      "SPORT            77\n",
      "ELU-O            66\n",
      "VÄLISMAA         63\n",
      "KULTUUR          52\n",
      "KRIMI            42\n",
      "Name: rubric, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.rubric.value_counts())\n",
    "print(val.rubric.value_counts())\n",
    "print(test.rubric.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac731825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.9 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Andmete loomine mudeli jaoks\n",
    "train_encodings = tokenizer(list(train[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "train_encodings[\"labels\"] = train[:200].rubric_idx\n",
    "train_dataset = Dataset.from_dict(train_encodings)\n",
    "\n",
    "val_encodings = tokenizer(list(val[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "val_encodings[\"labels\"] = val[:200].rubric_idx\n",
    "val_dataset = Dataset.from_dict(val_encodings)\n",
    "\n",
    "test_encodings = tokenizer(list(test[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "test_encodings[\"labels\"] = test[:200].rubric_idx\n",
    "test_dataset = Dataset.from_dict(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9094e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at train_results_mudel4/checkpoint-200000 were not used when initializing BertForSequenceClassification: ['cls_lemma.predictions.transform.dense.bias', 'cls_lemma.predictions.bias', 'cls_lemma.predictions.transform.LayerNorm.bias', 'cls_lemma.predictions.transform.LayerNorm.weight', 'cls_lemma.predictions.transform.dense.weight', 'cls_lemma.predictions.decoder.bias', 'cls_lemma.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at train_results_mudel4/checkpoint-200000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\rauln\\Documents\\makatoo\\transformers\\src\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n",
      "  Number of trainable parameters = 122061801\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 05:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.946861</td>\n",
       "      <td>0.821227</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.418326</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.835420</td>\n",
       "      <td>0.721806</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.480766</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=26, training_loss=1.9466438293457031, metrics={'train_runtime': 335.9926, 'train_samples_per_second': 1.191, 'train_steps_per_second': 0.077, 'total_flos': 52625518387200.0, 'train_loss': 1.9466438293457031, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mudeli kohandamine\n",
    "model = BertForSequenceClassification.from_pretrained(\"train_results/checkpoint-100000\", num_labels=len(rubriik_idx))\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "results_collection = []\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    predictions = [idx_rubriik[pred] for pred in predictions]\n",
    "    labels = [idx_rubriik[lab] for lab in labels]\n",
    "\n",
    "    results = classification_report(predictions, labels, output_dict=True)\n",
    "    results_collection.append(results)\n",
    "    return {\"precision\": results['weighted avg']['precision'], \"recall\": results['weighted avg']['recall'], \"f1\": results['weighted avg']['f1-score'], \"accuracy\": results[\"accuracy\"]}\n",
    "    \n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"Rubric_class_results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=2\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset= val_dataset,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43b02de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARVAMUS': {'precision': 0.9130434782608695, 'recall': 0.34146341463414637, 'f1-score': 0.4970414201183432, 'support': 123}, 'EESTI': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'ELU-O': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'KOMM-O-ELU': {'precision': 0.04, 'recall': 1.0, 'f1-score': 0.07692307692307693, 'support': 1}, 'KOMM-P-EESTI': {'precision': 0.4482758620689655, 'recall': 0.22413793103448276, 'f1-score': 0.2988505747126437, 'support': 58}, 'KRIMI': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'KULTUUR': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'SPORT': {'precision': 0.5454545454545454, 'recall': 0.46153846153846156, 'f1-score': 0.4999999999999999, 'support': 13}, 'VÄLISMAA': {'precision': 0.16666666666666666, 'recall': 0.6, 'f1-score': 0.2608695652173913, 'support': 5}, 'accuracy': 0.325, 'macro avg': {'precision': 0.2348267280501163, 'recall': 0.29190442302301006, 'f1-score': 0.18152051521905055, 'support': 200}, 'weighted avg': {'precision': 0.7313429512516469, 'recall': 0.325, 'f1-score': 0.4317534945544979, 'support': 200}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "predictions = [idx_rubriik[pred] for pred in predictions]\n",
    "labels = [idx_rubriik[lab] for lab in labels]\n",
    "\n",
    "results = classification_report(predictions, labels, output_dict=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37a4d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ESTBERT ###\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tartuNLP/EstBERT\", max_length = 128,\n",
    "                         padding = \"max_length\", truncation = True, return_tensors = \"pt\")\n",
    "train_encodings = tokenizer(list(train[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "train_encodings[\"labels\"] = train[:200].rubric_idx\n",
    "train_dataset = Dataset.from_dict(train_encodings)\n",
    "\n",
    "val_encodings = tokenizer(list(val[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "val_encodings[\"labels\"] = val[:200].rubric_idx\n",
    "val_dataset = Dataset.from_dict(val_encodings)\n",
    "\n",
    "test_encodings = tokenizer(list(test[:200].text), max_length = 128, padding = \"max_length\", \n",
    "                            truncation = True, return_tensors = \"pt\")\n",
    "test_encodings[\"labels\"] = test[:200].rubric_idx\n",
    "test_dataset = Dataset.from_dict(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d675741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tartuNLP/EstBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tartuNLP/EstBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "C:\\Users\\rauln\\Documents\\makatoo\\transformers\\src\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n",
      "  Number of trainable parameters = 124448265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 08:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.890342</td>\n",
       "      <td>0.924461</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.403413</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.804132</td>\n",
       "      <td>0.860580</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.448330</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=26, training_loss=1.8534036783071666, metrics={'train_runtime': 501.173, 'train_samples_per_second': 0.798, 'train_steps_per_second': 0.052, 'total_flos': 26312759193600.0, 'train_loss': 1.8534036783071666, 'epoch': 2.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"tartuNLP/EstBERT\", num_labels=len(rubriik_idx))\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "results_collection = []\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    predictions = [idx_rubriik[pred] for pred in predictions]\n",
    "    labels = [idx_rubriik[lab] for lab in labels]\n",
    "\n",
    "    results = classification_report(predictions, labels, output_dict=True)\n",
    "    results_collection.append(results)\n",
    "    return {\"precision\": results['weighted avg']['precision'], \"recall\": results['weighted avg']['recall'], \"f1\": results['weighted avg']['f1-score'], \"accuracy\": results[\"accuracy\"]}\n",
    "    \n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"Rubric_class_results_EST\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=2\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41700cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     ARVAMUS       0.98      0.32      0.48       148\n",
      "       EESTI       0.11      0.14      0.12        21\n",
      "       ELU-O       0.00      0.00      0.00         0\n",
      "  KOMM-O-ELU       0.22      0.28      0.24        18\n",
      "KOMM-P-EESTI       0.14      0.50      0.21         6\n",
      "       KRIMI       0.00      0.00      0.00         0\n",
      "     KULTUUR       0.00      0.00      0.00         0\n",
      "       SPORT       0.39      1.00      0.56         7\n",
      "    VÄLISMAA       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33       200\n",
      "   macro avg       0.20      0.25      0.18       200\n",
      "weighted avg       0.77      0.33      0.42       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "predictions = [idx_rubriik[pred] for pred in predictions]\n",
    "labels = [idx_rubriik[lab] for lab in labels]\n",
    "\n",
    "results = classification_report(predictions, labels, output_dict=True)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
