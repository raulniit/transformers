{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a7703d",
   "metadata": {},
   "source": [
    "# Magistritöö : BERT mudeli kohandamine eesti keelele\n",
    "\n",
    "## Taust\n",
    "\n",
    "Sisendtekst -> **tokenizer** -> **embedding** -> transformer\n",
    "\n",
    "Tavalises BERTis hakitakse sõna tokenizeris osadeks (täissõna või n-gram) ning sellest tehakse 3-komponendiline embedding (token embedding, segment embedding ja sequence embedding).\n",
    "\n",
    "* Token embedding - tokeni vektor \n",
    "* Segment embedding - 1/0 vektor paarissisendite eristamiseks\n",
    "* Sequence embedding - vektor, mis tähistab positsiooni sisendtekstis\n",
    "\n",
    "Embeddingud liidetakse ja saadakse sisendembedding transformerile.  \n",
    "Vaata siit:\n",
    "https://medium.com/@_init_/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a\n",
    "\n",
    "\n",
    "## Ülesanne\n",
    "\n",
    "Anda sisendiga kaasa rohkem infot, kasutades estnltk vahendeid (morfoloogia osad). Selleks on vaja:\n",
    "\n",
    "1) Muuta tokenizerit, et saada tokeni asemel lemma ja vorm  \n",
    "2) Muuta embeddinguid, tokem embeddingu asemel leida lemma embedding ja vormi embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff58f3b",
   "metadata": {},
   "source": [
    "## 1) Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9dd8b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 572, 3611, 11838, 1709, 49892, 229, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tavaline BERT tokenizer\n",
    "\n",
    "from transformers import BertTokenizer, PreTrainedTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"tartuNLP/EstBERT\")\n",
    "\n",
    "tokenizer(\"Kuidas kirjutada magistritööd?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2667998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mari', 'sg ad'), ('olema', 'b'), ('paha', 'sg n'), ('tuju', 'sg n'), (',', ''), ('aga', ''), ('see', 'sg n'), ('olema', 'b'), ('fine', 'sg n'), ('.', '')]\n",
      "\n",
      "{'input_ids': [(2, 2), (8316, 1), (788, 411), (2857, 1), (7015, 1), (11, 49881), (179, 49881), (126, 1), (788, 411), (1, 1), (15, 49881), (3, 3)], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# Uus tokeniseerija\n",
    "\n",
    "from src.transformers.models.bert.tokenization_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer(\"vocab.txt\")\n",
    "input_tekst = \"Maril on paha tuju, aga see on fine.\"\n",
    "\n",
    "print(tokenizer.tokenize(input_tekst))\n",
    "print(\"\")\n",
    "print(tokenizer(input_tekst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbb2b37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    2,     2],\n",
      "         [ 8316,     1],\n",
      "         [  788,   411],\n",
      "         [ 2857,     1],\n",
      "         [ 7015,     1],\n",
      "         [   11, 49881],\n",
      "         [  179, 49881],\n",
      "         [  126,     1],\n",
      "         [  788,   411],\n",
      "         [    1,     1],\n",
      "         [   15, 49881],\n",
      "         [    3,     3]]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer_output = tokenizer(input_tekst)\n",
    "words_tensor = torch.tensor([tokenizer_output[\"input_ids\"]])\n",
    "segments_tensor = torch.tensor([tokenizer_output[\"token_type_ids\"]])\n",
    "print(words_tensor)\n",
    "print(segments_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcf014",
   "metadata": {},
   "source": [
    "## 2) Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bb90748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tartuNLP/EstBERT were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'bert.embeddings.word_embeddings.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at tartuNLP/EstBERT and are newly initialized: ['bert.embeddings.form_embeddings.weight', 'bert.embeddings.lemma_embeddings.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from src.transformers.models.bert.modeling_bert import BertEmbeddings, BertModel\n",
    "from src.transformers.models.bert.configuration_bert import BertConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "config = BertConfig()\n",
    "embedding = BertEmbeddings(config)\n",
    "model = BertModel(config).from_pretrained(\"tartuNLP/EstBERT\")\n",
    "\n",
    "# model = BertModel(config) \n",
    "# Annab index out of range errorit, kuna tokeniseerija kasutab EstBERT vocab.txt faili\n",
    "# Kui sõnal pole vormi, siis hetkel on vasteks tühi sõne -> ID 49881\n",
    "# Tavalisel BERTil sõnastiku suurus ~30 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd332d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0670, -0.4643, -0.3942,  ..., -0.2698, -0.1209, -0.1286],\n",
      "         [-0.3832, -0.1994,  1.8395,  ..., -0.7417,  0.2582,  1.0315],\n",
      "         [-0.1101, -0.4827,  1.5438,  ..., -0.8496, -0.1393,  3.0713],\n",
      "         ...,\n",
      "         [ 0.4404, -0.1631,  1.8296,  ..., -0.5746,  0.1799,  2.4584],\n",
      "         [-0.4306, -0.3358,  1.5688,  ..., -0.4726,  0.5961,  0.3756],\n",
      "         [-0.2092, -0.1607,  0.0142,  ..., -0.8392,  0.1013, -0.0064]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.2727, -0.5788,  0.7369, -0.5138,  0.6122, -0.0200, -0.6871,  0.3304,\n",
      "          0.0658,  0.0090,  0.1095,  0.0501,  0.0930,  0.4894,  0.2567, -0.1889,\n",
      "         -0.7491,  0.0874, -0.1658,  0.3224,  0.7752, -0.1106, -0.4507, -0.0576,\n",
      "         -0.3789, -0.4304, -0.2049, -0.1836, -0.4341,  0.1879, -0.5059, -0.6251,\n",
      "         -0.1487,  0.4441, -0.4719,  0.7903, -0.1909, -0.7007, -0.4707, -0.5245,\n",
      "          0.3003, -0.8979, -0.3604, -0.4676, -0.2059, -0.1337,  0.4530, -0.5848,\n",
      "         -0.0112,  0.3009,  0.0682,  0.4614,  0.6138,  0.0114,  0.2473,  0.5421,\n",
      "          0.1328,  0.3037,  0.0548, -0.4700, -0.6993,  0.6584,  0.5930,  0.3834,\n",
      "         -0.0269, -0.0578,  0.0423, -0.8390, -0.3376,  0.4773, -0.1961, -0.0952,\n",
      "         -0.2644, -0.2640, -0.6255, -0.7063,  0.0207,  0.1008,  0.3731, -0.2607,\n",
      "          0.4078,  0.5378, -0.0235, -0.0817,  0.3770, -0.2321, -0.3900,  0.3393,\n",
      "         -0.3059, -0.4889,  0.1338, -0.2069,  0.1829,  0.1349,  0.4334, -0.5263,\n",
      "          0.1828, -0.4000, -0.6623, -0.4730, -0.1742, -0.1516, -0.3425,  0.6424,\n",
      "          0.2423,  0.5066, -0.8037,  0.5538,  0.0875,  0.1328, -0.6150,  0.7581,\n",
      "          0.0102, -0.2371, -0.1054,  0.2478, -0.3355,  0.0162, -0.0280, -0.5351,\n",
      "          0.0053,  0.3595, -0.3555,  0.3803, -0.2089,  0.8287, -0.4661,  0.5345,\n",
      "         -0.5429,  0.7644, -0.4121,  0.7580, -0.0115, -0.1117,  0.1321,  0.5794,\n",
      "         -0.6583, -0.1150, -0.3323,  0.5085,  0.0531,  0.0678, -0.3987,  0.6452,\n",
      "         -0.1696,  0.2101,  0.0118,  0.4984,  0.4300, -0.2938,  0.6333,  0.3297,\n",
      "          0.2993, -0.3128,  0.6781, -0.1896, -0.3998, -0.0066, -0.0518,  0.7696,\n",
      "         -0.7761,  0.0968, -0.7750, -0.4739,  0.1023, -0.4121, -0.8251, -0.2585,\n",
      "         -0.5331, -0.1970,  0.1687,  0.3559, -0.0845,  0.1278,  0.4624, -0.5541,\n",
      "          0.6539,  0.3226,  0.4574, -0.6668, -0.0168, -0.0540, -0.9304, -0.5323,\n",
      "          0.1325, -0.6613, -0.2013, -0.6739,  0.3951, -0.6417,  0.3166,  0.3724,\n",
      "         -0.0598, -0.3427, -0.5795, -0.0351, -0.6019,  0.0921,  0.1328,  0.2405,\n",
      "         -0.3130, -0.5432,  0.3139,  0.2268, -0.4705,  0.3805,  0.3860,  0.2208,\n",
      "         -0.3125,  0.0854,  0.4170,  0.7283, -0.2792, -0.0718, -0.6351,  0.0464,\n",
      "         -0.4892,  0.4190,  0.4382,  0.2654, -0.0203,  0.4278,  0.0011,  0.2601,\n",
      "         -0.1791,  0.5019,  0.6229, -0.4962, -0.2145,  0.1840, -0.4118,  0.5781,\n",
      "         -0.3199,  0.7905,  0.1096, -0.3595,  0.1441, -0.6323, -0.4500, -0.5551,\n",
      "          0.2002,  0.2994, -0.3513,  0.2050, -0.3108, -0.1964, -0.1313,  0.2596,\n",
      "          0.3253,  0.4322,  0.6054, -0.1818, -0.4276, -0.3521, -0.4935,  0.1285,\n",
      "          0.2159, -0.3435, -0.4512, -0.5608,  0.3764,  0.2253, -0.3240,  0.3649,\n",
      "          0.3013,  0.3916,  0.0141, -0.0549,  0.4012,  0.3658, -0.4251, -0.1879,\n",
      "         -0.1510, -0.7721,  0.5464,  0.0024,  0.3951, -0.6002, -0.5654,  0.6455,\n",
      "         -0.3822,  0.4183, -0.1343,  0.4375, -0.5433, -0.2719, -0.0874,  0.5819,\n",
      "         -0.6956,  0.7206,  0.1846, -0.0624,  0.3783, -0.5017,  0.2877,  0.3489,\n",
      "         -0.4286,  0.4259, -0.6279, -0.8612, -0.1800, -0.6194,  0.0216, -0.2441,\n",
      "         -0.2432, -0.4828,  0.2796, -0.3630,  0.1519,  0.2093,  0.0591, -0.6001,\n",
      "         -0.0576, -0.2931,  0.1788,  0.7930,  0.6421,  0.5374,  0.2514, -0.2630,\n",
      "         -0.5039,  0.4431, -0.7116,  0.4439, -0.1635,  0.2593,  0.3101, -0.6493,\n",
      "         -0.5745,  0.3048,  0.5053,  0.4474, -0.0997, -0.4280,  0.3182,  0.3346,\n",
      "          0.2409,  0.3425, -0.1364,  0.3201, -0.3224,  0.2912, -0.0248, -0.2623,\n",
      "         -0.1975, -0.2104, -0.7852,  0.4442,  0.6270, -0.1594, -0.1318, -0.6898,\n",
      "         -0.2204, -0.7645,  0.3145,  0.2385, -0.5615,  0.7818,  0.2426, -0.3654,\n",
      "         -0.0057, -0.4258,  0.0398,  0.6143, -0.2993, -0.1167, -0.1161,  0.0089,\n",
      "          0.1227, -0.3738,  0.6188,  0.1149, -0.2839,  0.4361,  0.2610,  0.1981,\n",
      "          0.1808,  0.7384,  0.5198, -0.0234, -0.5002,  0.8382, -0.3789, -0.0690,\n",
      "         -0.3937,  0.0915, -0.2840,  0.2261, -0.7205,  0.2070, -0.5138,  0.6378,\n",
      "          0.2122,  0.4103, -0.2519,  0.2411, -0.2879, -0.0158,  0.4097, -0.0128,\n",
      "         -0.5710, -0.3779, -0.0384, -0.4294, -0.2410, -0.0668,  0.1562,  0.3675,\n",
      "         -0.1158,  0.3652, -0.0425, -0.0625, -0.2936,  0.1429, -0.4531, -0.1179,\n",
      "          0.2624, -0.3601,  0.3595, -0.3718,  0.2275, -0.1774, -0.1658,  0.4106,\n",
      "         -0.1747,  0.0045, -0.0927, -0.0925, -0.4206, -0.0267,  0.6762, -0.2300,\n",
      "          0.4640, -0.2586, -0.5845,  0.0565, -0.0510,  0.0651,  0.4098,  0.2707,\n",
      "          0.6281, -0.6258,  0.2214, -0.1846,  0.7395,  0.2733, -0.0014, -0.9028,\n",
      "          0.2612, -0.3678, -0.1738, -0.2528,  0.0816, -0.3660, -0.7879, -0.4874,\n",
      "         -0.4026, -0.4612,  0.4941, -0.1895,  0.5352,  0.1332,  0.0893, -0.1834,\n",
      "         -0.4822, -0.0966,  0.3856, -0.2690, -0.4563, -0.1325, -0.0890,  0.2924,\n",
      "         -0.1987,  0.2286, -0.1905,  0.1124,  0.4164,  0.3379,  0.0252,  0.4358,\n",
      "          0.1216, -0.4913,  0.1487,  0.0351, -0.3880, -0.2719, -0.4070, -0.3255,\n",
      "         -0.0987, -0.4873, -0.0278,  0.3423,  0.2978,  0.4906, -0.2762, -0.4987,\n",
      "          0.7181,  0.0023, -0.6181,  0.6190, -0.0887,  0.2014, -0.6793, -0.5975,\n",
      "         -0.0331,  0.1320,  0.6615, -0.4479,  0.4940,  0.5999, -0.2698,  0.2195,\n",
      "         -0.2334, -0.7013,  0.6152,  0.4314,  0.2348, -0.4144,  0.4667, -0.4653,\n",
      "         -0.7812, -0.2820, -0.3843,  0.4979,  0.7548,  0.8034, -0.1796, -0.2653,\n",
      "          0.4037, -0.7528, -0.1239, -0.3652, -0.1561,  0.6621,  0.4521, -0.2228,\n",
      "          0.0752,  0.4224, -0.2210, -0.1503,  0.5507,  0.0734, -0.0233, -0.2534,\n",
      "          0.2511,  0.2551,  0.4264, -0.1195, -0.5831,  0.5628, -0.0613, -0.2985,\n",
      "         -0.8263,  0.7487, -0.3649, -0.1959,  0.5064, -0.6752,  0.5348, -0.3036,\n",
      "         -0.3951, -0.7332,  0.2066, -0.2376,  0.2240, -0.4509, -0.5346,  0.6826,\n",
      "         -0.5058, -0.1729, -0.4228,  0.2066,  0.4549, -0.6695,  0.4573, -0.2388,\n",
      "          0.0833,  0.1359,  0.3781, -0.9009, -0.3765, -0.4571,  0.4411,  0.1710,\n",
      "         -0.1305, -0.1765,  0.1502,  0.4751, -0.3407,  0.5130,  0.3432,  0.3377,\n",
      "         -0.3165,  0.1214,  0.4429, -0.4380,  0.5136,  0.3635,  0.4846, -0.0960,\n",
      "          0.3394,  0.4234,  0.1364, -0.0025, -0.0938, -0.5076, -0.1795,  0.6982,\n",
      "         -0.5108, -0.3058, -0.6003, -0.3000,  0.1856, -0.1768,  0.1089,  0.0633,\n",
      "          0.1387, -0.2966, -0.3256,  0.6132, -0.7490,  0.2704, -0.1347,  0.4990,\n",
      "         -0.5953,  0.0610,  0.3395,  0.0123,  0.0228,  0.5789,  0.4599, -0.5441,\n",
      "          0.5288, -0.1530, -0.6456,  0.7327, -0.1687,  0.0423,  0.0085, -0.1542,\n",
      "         -0.3576,  0.0085, -0.3998,  0.5356, -0.1592, -0.6664,  0.1646, -0.1690,\n",
      "         -0.2468,  0.3769,  0.0643,  0.3517, -0.3834,  0.3962,  0.4296, -0.8921,\n",
      "          0.0911,  0.4521,  0.4518,  0.3642, -0.2178,  0.1339, -0.0431, -0.6747,\n",
      "          0.4349,  0.1584, -0.3918, -0.1898, -0.6642, -0.1011,  0.3284,  0.2982,\n",
      "          0.2989, -0.4464, -0.6180,  0.4320,  0.1712, -0.3287, -0.5627, -0.3324,\n",
      "          0.0433, -0.3903, -0.2553, -0.7891,  0.7362, -0.5010,  0.0039, -0.7358,\n",
      "         -0.4367,  0.3078,  0.5681,  0.4494, -0.5264, -0.0250,  0.0845,  0.2669,\n",
      "          0.1791, -0.0835, -0.4819,  0.1718, -0.6916, -0.6804, -0.5152, -0.6139,\n",
      "         -0.3625,  0.5166,  0.2729,  0.2444,  0.1609,  0.3683,  0.4730, -0.6630,\n",
      "         -0.3337,  0.6883, -0.5913, -0.2827,  0.5628, -0.5717, -0.6170,  0.2711,\n",
      "          0.4143, -0.6368,  0.1157,  0.5691,  0.1969,  0.4402,  0.1148,  0.1674,\n",
      "         -0.8219, -0.2743, -0.4523,  0.1920,  0.5361,  0.1734, -0.0908, -0.4867,\n",
      "         -0.6544,  0.0871, -0.0294,  0.4496, -0.4681, -0.0161, -0.2008, -0.5274,\n",
      "          0.0728, -0.4423,  0.1706,  0.2212,  0.3854,  0.8463, -0.7891, -0.1151,\n",
      "         -0.2008, -0.6634, -0.3211, -0.0359,  0.0570,  0.4276, -0.3152, -0.4504,\n",
      "          0.1225,  0.3645, -0.3007,  0.3081, -0.1557, -0.7277, -0.6762,  0.4295]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(model(words_tensor, segments_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
