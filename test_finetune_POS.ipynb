{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5054b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from src.transformers import BertTokenizer, BertForTokenClassification, BertConfig, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e08dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"conllu/et_edt-ud-train.conllu\" ,mode = \"r\", encoding = \"utf8\") as f:\n",
    "    data_raw_train = f.read()\n",
    "    \n",
    "with open(\"conllu/et_edt-ud-test.conllu\" ,mode = \"r\", encoding = \"utf8\") as f:\n",
    "    data_raw_test = f.read()\n",
    "    \n",
    "with open(\"conllu/et_edt-ud-dev.conllu\" ,mode = \"r\", encoding = \"utf8\") as f:\n",
    "    data_raw_val = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b827f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = conllu.parse(data_raw_train)\n",
    "data_test = conllu.parse(data_raw_test)\n",
    "data_val = conllu.parse(data_raw_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27a17781",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paarid = []\n",
    "for lause in data_train:\n",
    "    train_paarid.append({\"lause\": [(token[\"form\"], token[\"upos\"]) for token in lause]})\n",
    "    \n",
    "test_paarid = []\n",
    "for lause in data_test:\n",
    "    test_paarid.append({\"lause\": [(token[\"form\"], token[\"upos\"]) for token in lause]})\n",
    "    \n",
    "val_paarid = []\n",
    "for lause in data_val:\n",
    "    val_paarid.append({\"lause\": [(token[\"form\"], token[\"upos\"]) for token in lause]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3824e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tags = list(set(token[1] for lause in train_paarid for token in lause[\"lause\"]))\n",
    "tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
    "idx2tag = {idx:tag for idx, tag in enumerate(tags)}\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file = \"vocab_final.txt\", vocab_file_form = \"vocab_form.txt\", max_length = 128,\n",
    "                         padding = \"max_length\", truncation = True, return_tensors = \"pt\", mask_token=\"ˇMASKˇ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44db7d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADJ', 28713),\n",
       " ('ADP', 7453),\n",
       " ('ADV', 33003),\n",
       " ('AUX', 17432),\n",
       " ('CCONJ', 12422),\n",
       " ('DET', 5398),\n",
       " ('INTJ', 251),\n",
       " ('NOUN', 91185),\n",
       " ('NUM', 7174),\n",
       " ('PRON', 18025),\n",
       " ('PROPN', 20927),\n",
       " ('PUNCT', 56377),\n",
       " ('SCONJ', 6752),\n",
       " ('SYM', 540),\n",
       " ('VERB', 38394),\n",
       " ('X', 857)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Info andmestike kohta\n",
    "\n",
    "from collections import Counter\n",
    "tags_train = [y[1] for x in train_paarid for y in x[\"lause\"]]\n",
    "c = Counter(tags_train)\n",
    "sorted(c.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef5bf0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344903"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x[1] for x in sorted(c.items())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60125f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADJ', 3992),\n",
       " ('ADP', 887),\n",
       " ('ADV', 4194),\n",
       " ('AUX', 2247),\n",
       " ('CCONJ', 1681),\n",
       " ('DET', 675),\n",
       " ('INTJ', 20),\n",
       " ('NOUN', 11655),\n",
       " ('NUM', 1080),\n",
       " ('PRON', 2469),\n",
       " ('PROPN', 2539),\n",
       " ('PUNCT', 7499),\n",
       " ('SCONJ', 859),\n",
       " ('SYM', 119),\n",
       " ('VERB', 4832),\n",
       " ('X', 61)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_val = [y[1] for x in val_paarid for y in x[\"lause\"]]\n",
    "c = Counter(tags_val)\n",
    "sorted(c.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca146185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44809"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x[1] for x in sorted(c.items())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2474baed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADJ', 4070),\n",
       " ('ADP', 914),\n",
       " ('ADV', 4861),\n",
       " ('AUX', 2575),\n",
       " ('CCONJ', 2031),\n",
       " ('DET', 812),\n",
       " ('INTJ', 51),\n",
       " ('NOUN', 12616),\n",
       " ('NUM', 848),\n",
       " ('PRON', 2524),\n",
       " ('PROPN', 3061),\n",
       " ('PUNCT', 7674),\n",
       " ('SCONJ', 1116),\n",
       " ('SYM', 26),\n",
       " ('VERB', 5254),\n",
       " ('X', 100)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_test = [y[1] for x in test_paarid for y in x[\"lause\"]]\n",
    "c = Counter(tags_test)\n",
    "sorted(c.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afbc651e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48533"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x[1] for x in sorted(c.items())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb752cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelite allignimine\n",
    "def tokeniseeri_lause_lisa_labelid(batch):\n",
    "    INP, TTI, BIN, ATT, LAB = [], [], [], [], []\n",
    "    for i, lause_paarid in enumerate(batch[\"lause\"]):\n",
    "        lause = [x[0] for x in lause_paarid]\n",
    "        labelid_alg = [x[1] for x in lause_paarid]\n",
    "        lause_sonade_tokenid = []\n",
    "        for sona in lause:\n",
    "            tokeniseeritud_sona = tokenizer(sona, estnltk_first_token = True)\n",
    "            lause_sonade_tokenid.append(tokeniseeritud_sona[\"input_ids\"][1:-1])\n",
    "\n",
    "        tokeneid_sonadel = [len(x) for x in lause_sonade_tokenid]\n",
    "        tokeniseeritud_lause = tokenizer(lause, is_split_into_words=True, max_length = 128,\n",
    "                         padding = \"max_length\", truncation = True, return_tensors = \"pt\", estnltk_first_token = True)\n",
    "        labelid = []\n",
    "        i = 0\n",
    "        mitu_id = False\n",
    "        j = 0\n",
    "        \n",
    "        for input_id in tokeniseeritud_lause[\"input_ids\"][0]:\n",
    "            \n",
    "            if mitu_id:\n",
    "                labelid.append(-100)\n",
    "                j -= 1\n",
    "                if j == 0:\n",
    "                    mitu_id = False\n",
    "                continue\n",
    "                \n",
    "            if input_id[0].item() < 5:\n",
    "                labelid.append(-100)\n",
    "                continue\n",
    "                \n",
    "            labelid.append(tag2idx[labelid_alg[i]])\n",
    "            \n",
    "            if tokeneid_sonadel[i] > 1:\n",
    "                j = tokeneid_sonadel[i] - 1\n",
    "                mitu_id = True\n",
    "                \n",
    "            i += 1\n",
    "            \n",
    "        assert len(tokeniseeritud_lause[\"input_ids\"][0]) == len(labelid)\n",
    "        \n",
    "        INP.append(tokeniseeritud_lause[\"input_ids\"])\n",
    "        TTI.append(tokeniseeritud_lause[\"token_type_ids\"])\n",
    "        BIN.append(tokeniseeritud_lause[\"binary_channels\"])\n",
    "        ATT.append(tokeniseeritud_lause[\"attention_mask\"])\n",
    "        LAB.append(torch.tensor(labelid))\n",
    "    \n",
    "    \n",
    "    INP = torch.cat(INP)\n",
    "    TTI = torch.cat(TTI)\n",
    "    BIN = torch.cat(BIN)\n",
    "    ATT = torch.cat(ATT)\n",
    "    LAB = torch.stack(LAB)\n",
    "    \n",
    "    encodings = {\n",
    "    \"input_ids\" : INP,\n",
    "    \"token_type_ids\" : TTI,\n",
    "    \"binary_channels\" : BIN,\n",
    "    \"attention_mask\" : ATT,\n",
    "    \"labels\" : LAB\n",
    "    }\n",
    "    \n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf14fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:fingerprint.py:328: Parameter 'function'=<function tokeniseeri_lause_lisa_labelid at 0x000001E907F8E550> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a64251869d466dbad6e3ad1ed3944b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3b82f135914db096d39a91ed602a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0beeec89244e6199ec3edf7211e3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 2s\n",
      "Wall time: 6min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = Dataset.from_list(train_paarid)\n",
    "train_tokenized_dataset = train_dataset.map(tokeniseeri_lause_lisa_labelid, batched=True)\n",
    "\n",
    "test_dataset = Dataset.from_list(test_paarid)\n",
    "test_tokenized_dataset = test_dataset.map(tokeniseeri_lause_lisa_labelid, batched=True)\n",
    "\n",
    "val_dataset = Dataset.from_list(val_paarid)\n",
    "val_tokenized_dataset = val_dataset.map(tokeniseeri_lause_lisa_labelid, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9deb874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file train_results_mudel4/checkpoint-200000\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"hidden_size_form\": 48,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50005,\n",
      "  \"vocab_size_form\": 111\n",
      "}\n",
      "\n",
      "loading weights file train_results_mudel4/checkpoint-200000\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at train_results_mudel4/checkpoint-200000 were not used when initializing BertForTokenClassification: ['cls_lemma.predictions.transform.dense.weight', 'cls_lemma.predictions.transform.LayerNorm.bias', 'cls_lemma.predictions.transform.dense.bias', 'cls_lemma.predictions.decoder.weight', 'cls_lemma.predictions.transform.LayerNorm.weight', 'cls_lemma.predictions.decoder.bias', 'cls_lemma.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at train_results_mudel4/checkpoint-200000 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lause. If lause are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n",
      "  Number of trainable parameters = 121476592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 15:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.802881</td>\n",
       "      <td>0.571957</td>\n",
       "      <td>0.505303</td>\n",
       "      <td>0.532034</td>\n",
       "      <td>0.505303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lause. If lause are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=1.7916983952597967, metrics={'train_runtime': 916.1842, 'train_samples_per_second': 1.091, 'train_steps_per_second': 0.069, 'total_flos': 130664914944000.0, 'train_loss': 1.7916983952597967, 'epoch': 1.0})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"train_results/checkpoint-100000\", num_labels=len(tag2idx))\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"POS_tag_results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [[tags[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[tags[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    \n",
    "    results = classification_report(np.hstack(true_predictions).tolist(), np.hstack(true_labels).tolist(), output_dict=True)\n",
    "    return {\"precision\": results['weighted avg']['precision'], \"recall\": results['weighted avg']['recall'], \"f1\": results['weighted avg']['f1-score'], \"accuracy\": results[\"accuracy\"]}\n",
    "    \n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=val_tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d8c4a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lause. If lause are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.22      0.43      0.29        60\n",
      "         ADP       0.00      0.00      0.00         0\n",
      "         ADV       0.63      0.45      0.52       152\n",
      "         AUX       0.69      0.72      0.70        60\n",
      "       CCONJ       0.57      0.62      0.59        52\n",
      "         DET       0.00      0.00      0.00         0\n",
      "        INTJ       0.00      0.00      0.00         0\n",
      "        NOUN       0.77      0.60      0.67       440\n",
      "         NUM       0.04      1.00      0.08         1\n",
      "        PRON       0.65      0.59      0.62        56\n",
      "       PROPN       0.12      0.45      0.19        22\n",
      "       PUNCT       0.76      0.59      0.66       173\n",
      "       SCONJ       0.36      0.62      0.46        13\n",
      "        VERB       0.64      0.63      0.64       126\n",
      "\n",
      "    accuracy                           0.58      1155\n",
      "   macro avg       0.39      0.48      0.39      1155\n",
      "weighted avg       0.67      0.58      0.61      1155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(test_tokenized_dataset)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [tags[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [tags[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = classification_report(np.hstack(true_predictions).tolist(), np.hstack(true_labels).tolist())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "19dac77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e99b85cea945af9c3fa31eb5025b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81418d97c8cd4ab391c1a26034c067a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dd16daaf0d475b99d097e091cb8d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.09 s\n",
      "Wall time: 2.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### ESTBERT ###\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tartuNLP/EstBERT\", max_length = 128,\n",
    "                         padding = \"max_length\", truncation = True, return_tensors = \"pt\")\n",
    "\n",
    "def tokeniseeri_lause_lisa_labelid(batch):\n",
    "    INP, TTI, ATT, LAB = [], [], [], []\n",
    "    for i, lause_paarid in enumerate(batch[\"lause\"]):\n",
    "        lause = [x[0] for x in lause_paarid]\n",
    "        labelid_alg = [x[1] for x in lause_paarid]\n",
    "        lause_sonade_tokenid = []\n",
    "        for sona in lause:\n",
    "            tokeniseeritud_sona = tokenizer(sona)\n",
    "            lause_sonade_tokenid.append(tokeniseeritud_sona[\"input_ids\"][1:-1])\n",
    "\n",
    "        tokeneid_sonadel = [len(x) for x in lause_sonade_tokenid]\n",
    "        tokeniseeritud_lause = tokenizer(lause, is_split_into_words=True, max_length = 128,\n",
    "                         padding = \"max_length\", truncation = True, return_tensors = \"pt\")\n",
    "        labelid = []\n",
    "        i = 0\n",
    "        mitu_id = False\n",
    "        j = 0\n",
    "\n",
    "        for input_id in tokeniseeritud_lause[\"input_ids\"][0]:\n",
    "\n",
    "            if mitu_id:\n",
    "                labelid.append(-100)\n",
    "                j -= 1\n",
    "                if j == 0:\n",
    "                    mitu_id = False\n",
    "                continue\n",
    "\n",
    "            if input_id.item() < 5:\n",
    "                labelid.append(-100)\n",
    "                continue\n",
    "\n",
    "\n",
    "            labelid.append(tag2idx[labelid_alg[i]])\n",
    "\n",
    "            if tokeneid_sonadel[i] > 1:\n",
    "                j = tokeneid_sonadel[i] - 1\n",
    "                mitu_id = True\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        assert len(tokeniseeritud_lause[\"input_ids\"][0]) == len(labelid)\n",
    "\n",
    "        INP.append(tokeniseeritud_lause[\"input_ids\"])\n",
    "        TTI.append(tokeniseeritud_lause[\"token_type_ids\"])\n",
    "        ATT.append(tokeniseeritud_lause[\"attention_mask\"])\n",
    "        LAB.append(torch.tensor(labelid))\n",
    "    \n",
    "    \n",
    "    INP = torch.cat(INP)\n",
    "    TTI = torch.cat(TTI)\n",
    "    ATT = torch.cat(ATT)\n",
    "    LAB = torch.stack(LAB)\n",
    "    \n",
    "    encodings = {\n",
    "    \"input_ids\" : INP,\n",
    "    \"token_type_ids\" : TTI,\n",
    "    \"attention_mask\" : ATT,\n",
    "    \"labels\" : LAB\n",
    "    }\n",
    "    \n",
    "    return encodings\n",
    "\n",
    "train_dataset = Dataset.from_list(train_paarid)\n",
    "train_tokenized_dataset = train_dataset.map(tokeniseeri_lause_lisa_labelid, batched=True)\n",
    "\n",
    "test_dataset = Dataset.from_list(test_paarid)\n",
    "test_tokenized_dataset = test_dataset.map(tokeniseeri_lause_lisa_labelid, batched=True)\n",
    "\n",
    "val_dataset = Dataset.from_list(val_paarid)\n",
    "val_tokenized_dataset = val_dataset.map(tokeniseeri_lause_lisa_labelid, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a74f9bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tartuNLP/EstBERT were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at tartuNLP/EstBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lause. If lause are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n",
      "  Number of trainable parameters = 123863056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 13:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.648088</td>\n",
       "      <td>0.894705</td>\n",
       "      <td>0.856150</td>\n",
       "      <td>0.871951</td>\n",
       "      <td>0.856150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lause. If lause are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=1.2351588900127108, metrics={'train_runtime': 836.1137, 'train_samples_per_second': 1.196, 'train_steps_per_second': 0.075, 'total_flos': 65332457472000.0, 'train_loss': 1.2351588900127108, 'epoch': 1.0})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"tartuNLP/EstBERT\", num_labels=len(tag2idx))\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"POS_tag_results_EST\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [[tags[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[tags[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    \n",
    "    results = classification_report(np.hstack(true_predictions).tolist(), np.hstack(true_labels).tolist(), output_dict=True)\n",
    "    return {\"precision\": results['weighted avg']['precision'], \"recall\": results['weighted avg']['recall'], \"f1\": results['weighted avg']['f1-score'], \"accuracy\": results[\"accuracy\"]}\n",
    "    \n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=val_tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a463cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lause. If lause are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.64      0.81      0.71        95\n",
      "         ADP       0.00      0.00      0.00         0\n",
      "         ADV       0.77      0.77      0.77       111\n",
      "         AUX       0.95      0.95      0.95        62\n",
      "       CCONJ       0.97      0.92      0.94        61\n",
      "         DET       0.00      0.00      0.00         0\n",
      "        INTJ       0.00      0.00      0.00         0\n",
      "        NOUN       0.94      0.83      0.88       402\n",
      "         NUM       0.62      1.00      0.77        15\n",
      "        PRON       0.88      0.82      0.85        55\n",
      "       PROPN       0.82      0.80      0.81        93\n",
      "       PUNCT       1.00      0.98      0.99       188\n",
      "       SCONJ       0.68      0.94      0.79        16\n",
      "        VERB       0.97      0.89      0.93       141\n",
      "\n",
      "    accuracy                           0.86      1239\n",
      "   macro avg       0.66      0.69      0.67      1239\n",
      "weighted avg       0.90      0.86      0.88      1239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rauln\\anaconda3\\envs\\EKTP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(test_tokenized_dataset)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "true_predictions = [\n",
    "    [tags[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [tags[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = classification_report(np.hstack(true_predictions).tolist(), np.hstack(true_labels).tolist())\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
